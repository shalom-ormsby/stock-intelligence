# Sage Stocks Architecture

*Last updated: November 19, 2025*

**Development Version:** v1.2.16 (Complete) - Stock Events Ingestion Pipeline
**Latest Feature:** v1.2.16 (Complete) - FMP Event Calendar Integration (Earnings, Dividends, Splits)
**Template Version:** v0.1.0 (Beta) - Launching with Cohort 1
**Production URL:** [https://sagestocks.vercel.app](https://sagestocks.vercel.app)
**Status:** âœ… Live in Production - Fully Automated

> ğŸ“‹ **Versioning Note:** This document uses **development versions** (v1.x, v2.x) for technical milestone tracking. See [CHANGELOG.md](CHANGELOG.md) "ğŸ“‹ Versioning Strategy (Dual-Track)" for the mapping to user-facing template versions (v0.1.0 Beta â†’ v1.0.0 Public).
>
> **Current Mapping:** Template v0.1.0 (Beta) includes development versions v1.0.0â€“v1.1.6

---

## Table of Contents

1. [System Overview](#system-overview)
2. [Technology Stack](#technology-stack)
3. [Data Flow Diagram](#data-flow-diagram-v102)
4. [Architecture Diagram](#architecture-diagram-v102)
5. [Component Structure](#component-structure)
6. [Data Flow](#data-flow)
7. [API Endpoints](#api-endpoints)
8. [External Integrations](#external-integrations)
9. [Rate Limiting Architecture](#rate-limiting-architecture)
10. [Security Model](#security-model)
11. [Deployment Architecture](#deployment-architecture)
12. [Configuration](#configuration)
13. [Design Decisions](#design-decisions)

---

## System Overview

Sage Stocks is a **serverless stock analysis platform** that delivers automated technical and fundamental analysis with AI-generated insights. Built as a multi-user SaaS platform with OAuth authentication, it's designed for daily decision-support with Notion as the primary data store.

**Core Capabilities:**
- **Multi-user OAuth authentication** - Notion OAuth with session-based access control (v1.1.x)
- **Real-time stock analysis** - Technical + fundamental indicators from FMP and FRED APIs
- **6-dimension scoring system** - 5 weighted (Technical 28.5%, Fundamental 33%, Macro 19%, Risk 14.5%, Market Alignment 5%) + Sentiment (reference-only, 0% weight in composite)
- **Market context awareness** - Regime detection (Risk-On, Risk-Off, Transition) with sector rotation tracking (v1.0.7)
- **Stock events calendar** - Automated ingestion of earnings calls, dividends, and stock splits for Portfolio/Watchlist stocks (v1.2.16)
- **LLM-generated analysis** - 7-section regime-aware analysis narratives (Google Gemini Flash 2.5, $0.013/analysis)
- **Historical context tracking** - Delta tracking across previous analyses
- **Template version management** - User-controlled upgrade system with data preservation (v1.1.6)
- **Timezone-aware rate limiting** - User-specific quotas with admin bypass (Upstash Redis)
- **Notion Inbox notifications** - Built-in status updates (v1.0.0)
- **API cost monitoring** - Real-time dashboard for operational visibility (v1.0.2c)

**Design Philosophy:** *Impeccable but simple.* Built for daily stock analyses ahead of earnings, not enterprise-scale deployment. Notion-first architecture with potential PostgreSQL migration in v2.0 (Q1-Q2 2026).

**âš ï¸ DEPRECATED COMPONENTS:**
- **WordPress hosting** (deprecated v1.1.0) - Previously used shalomormsby.com/stock-intelligence, now fully migrated to sagestocks.vercel.app
- **Alpha Vantage API** (deprecated v0.4.0) - Migrated to FMP for all stock data
- **Single-user hardcoded approach** (deprecated v1.1.0) - Replaced with OAuth multi-user system

---

## Technology Stack

### Runtime & Platform
- **Platform:** Vercel Serverless Functions
- **Production URL:** [sagestocks.vercel.app](https://sagestocks.vercel.app)
- **Runtime:** Node.js 18+
- **Language:** TypeScript 5.3+
- **Build System:** tsc (TypeScript compiler)
- **Plan:** Vercel Pro ($20/month) - Required for 300-second timeout on analysis endpoint

### Data Sources
- **Financial Modeling Prep (FMP)** - Stock data, fundamentals, technical indicators, sector ETF performance, event calendars (v1.2.16: earnings, dividends, stock splits)
- **FRED API** - Macroeconomic indicators (yield curve, VIX, consumer sentiment)
- **Upstash Redis** - Distributed state for rate limiting + market context caching (1-hour TTL, optional - v1.0.7)

### LLM Integration
- **Google Gemini Flash 2.5** (Primary) - Analysis generation, $0.013 per analysis, 50% token reduction vs GPT-4
- **LLM Abstraction Layer** (v1.0.2) - Provider-agnostic interface supporting:
  - Google Gemini (Flash 2.5, Flash 1.5)
  - OpenAI (GPT-4 Turbo, GPT-3.5 Turbo)
  - Anthropic (Claude 3.5 Sonnet, Claude 3 Haiku)
  - Configurable via `LLM_PROVIDER` environment variable
  - Easy provider switching for cost/performance optimization

### Authentication & User Management
- **Notion OAuth** (v1.1.1) - Official OAuth 2.0 integration
- **Session Management** - Encrypted session tokens with secure cookie storage
- **Beta Users Database** - Notion-based user registry with approval workflow
- **Role-Based Access** - Admin, approved, pending, denied user states
- **Template Detection** - Auto-discovery of user's Notion databases (v1.1.6)

### Integration Layer
- **Notion API v2025-09-03** (v1.2.4) - Primary data store for Stock Analyses, Stock History, Beta Users databases
  - **SDK:** `@notionhq/client` v5.4.0 (upgraded from v2.3.0)
  - **Multi-source database support** with data source ID resolution pattern
  - **Data source caching** to minimize API calls (in-memory cache per client instance)
  - **Breaking changes resolved:** Migrated from `databases.query()` â†’ `dataSources.query()`
  - **Query pattern:** Fetch data source ID from database before queries (cached for performance)
- **Upstash Redis** - Rate limiting state and admin bypass sessions (REST API, serverless-friendly)
- **PostgreSQL (Supabase)** - Planned migration in v2.0 for performance optimization
- **REST APIs** - All external communication via HTTP

### Rate Limiting & Monitoring
- **Upstash Redis** - Distributed rate limiting with automatic midnight UTC reset
- **User Quotas** - 5 analyses per day for beta users, configurable per user
- **Admin Bypass** - Environment-based admin auto-bypass system
- **API Cost Dashboard** - Real-time monitoring of 6 API integrations (v1.0.2c)

### Development Tools
- **ESLint** - Code linting
- **ts-node** - Local testing scripts
- **dotenv** - Environment variable management
- **Vercel CLI** - Local development server

## Data Flow Diagram (v1.0.2)

# Stock Analyses Data Flow

```

## 1. User Authentication & Input
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  sagestocks.vercel.app         â”‚
â”‚  (Next.js/HTML Frontend)        â”‚
â”‚                                 â”‚
â”‚  1. Notion OAuth Login          â”‚
â”‚  2. Session validation          â”‚
â”‚  3. User enters ticker symbol   â”‚
â”‚  4. Clicks "Analyze"            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼

## 2. API Request with Authentication
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /api/analyze              â”‚
â”‚  (300s timeout on Pro plan)     â”‚
â”‚                                 â”‚
â”‚  Headers:                       â”‚
â”‚  - Session token (encrypted)    â”‚
â”‚  - User ID from session         â”‚
â”‚                                 â”‚
â”‚  Body: { ticker, userId }       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Session Validation             â”‚
â”‚  - Decrypt session token        â”‚
â”‚  - Verify Notion OAuth token    â”‚
â”‚  - Check user approval status   â”‚
â”‚  - Reject if pending/denied     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼

## 3. Data Ingestion (Parallel)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FMP API     â”‚        â”‚  FRED API    â”‚
â”‚  - Price     â”‚        â”‚  - Macro     â”‚
â”‚  - Volume    â”‚        â”‚  - Economic  â”‚
â”‚  - Technical â”‚        â”‚  - Rates     â”‚
â”‚  - Fundamental        â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼

## 4. LLM Processing
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM Abstraction Layer         â”‚
â”‚   (Gemini / Claude / OpenAI)    â”‚
â”‚                                 â”‚
â”‚  Input:                         â”‚
â”‚  - Raw financial metrics        â”‚
â”‚  - Price & volume data          â”‚
â”‚  - Technical indicators         â”‚
â”‚  - Macro context                â”‚
â”‚                                 â”‚
â”‚  Output:                        â”‚
â”‚  - Recommendation               â”‚
â”‚  - Composite scores (0-5)       â”‚
â”‚  - Pattern detection            â”‚
â”‚  - AI summary                   â”‚
â”‚  - Full markdown analysis       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼

## 5. Notion Write (Sequential bottleneck)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Notion API Write                       â”‚
â”‚  (Rate limits: ~3 rps, 100 blocks/call) â”‚
â”‚                                         â”‚
â”‚  Two targets:                           â”‚
â”‚  A) Main Stock Page                     â”‚
â”‚     â””â”€ Overwrite with latest analysis   â”‚
â”‚                                         â”‚
â”‚  B) Stock History Archive               â”‚
â”‚     â””â”€ Create timestamped snapshot      â”‚
â”‚                                         â”‚
â”‚  Operations:                            â”‚
â”‚  1. Update page properties (metadata)   â”‚
â”‚  2. Delete old content blocks           â”‚
â”‚  3. Write new content blocks            â”‚
â”‚     (batched due to size)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼

## 6. Database Update
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stock Analyses Database        â”‚
â”‚  @Stock Analyses                   â”‚
â”‚                                 â”‚
â”‚  Updated properties:            â”‚
â”‚  - Status: "Complete"           â”‚
â”‚  - All metric columns           â”‚
â”‚  - Scores & ratings             â”‚
â”‚  - Analysis Date                â”‚
â”‚  - API Calls Used               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼

## 7. Response & UI
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web App Frontend               â”‚
â”‚                                 â”‚
â”‚  - Stop "Analyzing..." spinner  â”‚
â”‚  - Display success              â”‚
â”‚  - "View Results in Notion"     â”‚
â”‚    button (redirects to page)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## Data Schema in Notion

```
Each analysis page contains:

â”œâ”€ Properties (50+ columns in database)
â”‚  â”œâ”€ Core: Ticker, Status, Analysis Date
â”‚  â”œâ”€ Price: Current, 50/200 MA, 52W High/Low
â”‚  â”œâ”€ Scores: Composite, Technical, Fundamental, Macro, Risk, Sentiment, Sector
â”‚  â”œâ”€ Indicators: RSI, MACD, Volume, Beta, Volatility
â”‚  â”œâ”€ Fundamental: P/E, EPS, Market Cap, Debt/Equity
â”‚  â””â”€ Meta: Confidence, Data Quality Grade, API Calls
â”‚
â””â”€ Page Content (markdown)
â”œâ”€ Recommendation callout (colored, emoji)
â”œâ”€ Executive Summary
â”œâ”€ Technical Analysis
â”œâ”€ Fundamental Analysis
â”œâ”€ Macro & Sector Context
â”œâ”€ Catalysts & Events
â”œâ”€ Risks & Considerations
â”œâ”€ Trade Setup (entry/exit/stops in table)
â””â”€ Position Sizing Guidance

```

---

## Architecture Diagram (v1.0.2)

**Current architecture with OAuth authentication and multi-user support (v1.1.6)**

> âš ï¸ **DEPRECATED:** WordPress hosting at shalomormsby.com/stock-intelligence (v1.1.0). All references replaced with sagestocks.vercel.app.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              sagestocks.vercel.app (Production)                   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                  Frontend Pages (HTML/JS)                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ / (index.html) - OAuth Login                         â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Notion OAuth "Sign In" button                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Approval status display                            â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Redirect to /analyze after approval                â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ /analyze.html - Stock Analyzer                       â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Ticker Input Field                                 â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ "Analyze Stock" Button                            â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Real-time Status Display                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Usage Counter (X/5 today, user-specific)          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ "View Results" Link (opens Notion page)           â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Tailwind CSS + Vanilla JS (no build step)         â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ /settings.html - User Settings                       â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Bypass code activation                             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Usage statistics                                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Expiration countdown                               â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ /setup.html - Template Setup (v1.1.6)                â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Auto-detect Stock Analyses database                â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Auto-detect Stock History database                 â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Auto-detect Sage Stocks page                       â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Template version tracking                          â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ POST /api/analyze
                              â”‚ Headers: Session token
                              â”‚ Body: { ticker, userId }
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Vercel Serverless (v1.0.2)                  â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                      API Endpoints                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚ /analyze â”‚  â”‚ /webhookâ”‚  â”‚ /usage â”‚  â”‚  /bypass   â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  (NEW)   â”‚  â”‚ /health â”‚  â”‚        â”‚  â”‚            â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚       â”‚                          â”‚             â”‚           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚          â”‚                          â”‚             â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Core Libraries                           â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Rate Limiter â”‚  â”‚ Scoring      â”‚  â”‚ Notion Client   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - Admin      â”‚  â”‚ - 6 Scores   â”‚  â”‚ - Read History  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   Bypass     â”‚  â”‚ - Technical  â”‚  â”‚ - Write Pages   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - Session    â”‚  â”‚ - Fundamentalâ”‚  â”‚ - Child Pages   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   Check      â”‚  â”‚ - Macro/Risk â”‚  â”‚ - Archive       â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚         â”‚                 â”‚                    â”‚           â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ LLM Provider â”‚  â”‚ FMP Client   â”‚  â”‚ FRED Client    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ (NEW)        â”‚  â”‚ - Quotes     â”‚  â”‚ - Macro Data   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - Gemini     â”‚  â”‚ - Financials â”‚  â”‚ - Indicators   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - OpenAI     â”‚  â”‚ - Technicals â”‚  â”‚                â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ - Anthropic  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”‚ - Abstractionâ”‚                                         â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚ â”‚
â”‚  â”‚         â”‚                                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        â”‚        â”‚              â”‚              â”‚            â”‚
    â–¼        â–¼        â–¼              â–¼              â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Upstash â”‚ â”‚ Google â”‚ â”‚   FMP    â”‚ â”‚  FRED  â”‚ â”‚  Notion  â”‚ â”‚  Notion  â”‚
â”‚  Redis  â”‚ â”‚ Gemini â”‚ â”‚(Financialâ”‚ â”‚ (Macro â”‚ â”‚ Analyses â”‚ â”‚ History  â”‚
â”‚         â”‚ â”‚        â”‚ â”‚   Data)  â”‚ â”‚ Econ)  â”‚ â”‚    DB    â”‚ â”‚    DB    â”‚
â”‚ Rate    â”‚ â”‚ Flash  â”‚ â”‚          â”‚ â”‚        â”‚ â”‚          â”‚ â”‚          â”‚
â”‚ Limit + â”‚ â”‚  2.5   â”‚ â”‚ $22-29/  â”‚ â”‚  Free  â”‚ â”‚ Current  â”‚ â”‚ Archive  â”‚
â”‚ Bypass  â”‚ â”‚        â”‚ â”‚  month   â”‚ â”‚        â”‚ â”‚ Analysis â”‚ â”‚Time-     â”‚
â”‚Sessions â”‚ â”‚ $0.013/â”‚ â”‚          â”‚ â”‚        â”‚ â”‚          â”‚ â”‚Series    â”‚
â”‚         â”‚ â”‚analysisâ”‚ â”‚          â”‚ â”‚        â”‚ â”‚          â”‚ â”‚          â”‚
â”‚  Free   â”‚ â”‚(50% â†“) â”‚ â”‚          â”‚ â”‚        â”‚ â”‚          â”‚ â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**v1.1.6 Workflow (OAuth â†’ Analyze â†’ Notion):**
1. User visits [sagestocks.vercel.app](https://sagestocks.vercel.app) â†’ clicks "Sign in with Notion"
2. Notion OAuth flow â†’ user grants access â†’ redirected to /analyze.html
3. User enters ticker â†’ clicks "Analyze Stock"
4. HTML page â†’ POST /api/analyze (with session token in headers)
5. Vercel validates session â†’ checks user approval status
6. Checks rate limit (admin auto-bypass or 5/day per user)
7. Fetches market data (FMP + FRED in parallel)
8. Calculates 6 category scores + composite (Technical 30%, Fundamental 35%, Macro 20%, Risk 15%)
9. Queries Notion for historical analyses (5 most recent from user's Stock History DB)
10. Computes deltas and trends
11. Calls Gemini Flash 2.5 for 7-section analysis (~10-20 sec)
12. Writes to 3 Notion locations in user's workspace:
    - Stock Analyses DB (main page update, triggers Notion Inbox notification)
    - Child analysis page (dated, e.g., "AAPL Analysis - Nov 1, 2025")
    - Stock History DB (archive entry with timestamp)
13. Returns pageUrl â†’ HTML displays "View Results in Notion" link
14. User clicks â†’ opens their personal Notion analysis page

**Performance:** 25-35 seconds (Notion bottleneck: historical queries + 3 writes, improved with v1.0.5/v1.0.6 chunked streaming optimizations)
**Target:** 18-25 seconds
**Future:** v2.0 migration to PostgreSQL â†’ 18-25 seconds (10-15x faster DB ops)

---

## Future Architecture (v2.0)

**Next.js Frontend + PostgreSQL Database for production scale**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Next.js 14 App (Vercel Hosted)                   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Authentication (Supabase Auth)                            â”‚ â”‚
â”‚  â”‚  â€¢ Login / Signup / Password Reset                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Analyzer Page                                             â”‚ â”‚
â”‚  â”‚  â€¢ Ticker Input â†’ Real-time Status â†’ Results Display       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Historical Analysis View                                  â”‚ â”‚
â”‚  â”‚  â€¢ List of Past Analyses (sortable, filterable)            â”‚ â”‚
â”‚  â”‚  â€¢ Trend Charts (Recharts - score over time)              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Dashboard                                                 â”‚ â”‚
â”‚  â”‚  â€¢ Portfolio Overview                                      â”‚ â”‚
â”‚  â”‚  â€¢ Watchlist (track multiple tickers)                      â”‚ â”‚
â”‚  â”‚  â€¢ Usage Stats                                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Vercel API (same backend, minimal changes)
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Vercel API (v2.0 - PostgreSQL)                   â”‚
â”‚                                                                   â”‚
â”‚  Replace Notion queries with SQL:                                â”‚
â”‚  â€¢ Historical query: <500ms (vs 2-5 sec with Notion)              â”‚
â”‚  â€¢ Database writes: <100ms (vs 6-10 sec with Notion)              â”‚
â”‚  â€¢ Delta computation: Automatic with SQL window functions         â”‚
â”‚                                                                   â”‚
â”‚  Same: Rate limiting, Scoring, LLM generation, FMP/FRED clients   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â–¼         â–¼         â–¼           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Supabase  â”‚ â”‚ Redis  â”‚ â”‚ LLM  â”‚ â”‚FMP/FREDâ”‚
            â”‚PostgreSQL â”‚ â”‚(Rate   â”‚ â”‚      â”‚ â”‚        â”‚
            â”‚           â”‚ â”‚Limit)  â”‚ â”‚      â”‚ â”‚        â”‚
            â”‚ â€¢ analysesâ”‚ â”‚        â”‚ â”‚      â”‚ â”‚        â”‚
            â”‚ â€¢ users   â”‚ â”‚        â”‚ â”‚      â”‚ â”‚        â”‚
            â”‚ â€¢ watch-  â”‚ â”‚        â”‚ â”‚      â”‚ â”‚        â”‚
            â”‚   lists   â”‚ â”‚        â”‚ â”‚      â”‚ â”‚        â”‚
            â”‚           â”‚ â”‚        â”‚ â”‚      â”‚ â”‚        â”‚
            â”‚ $0-25/mo  â”‚ â”‚  Free  â”‚ â”‚$39/moâ”‚ â”‚$29/mo  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**v2.0 Performance:** 18-25 seconds (60-100x faster DB ops)
**v2.0 Features:** Trend charts, watchlists, portfolio tracking, mobile app
**v2.0 Timeline:** December 2025 - January 2026 (25-35 hours)

---

## Detailed System Flow (v1.0.2)

**Complete end-to-end flow for HTML Analyzer Page with LLM-generated analysis**

### Phase 1: OAuth Authentication & Session Setup

> âš ï¸ **DEPRECATED:** WordPress password gate replaced with Notion OAuth (v1.1.1). Hardcoded userId replaced with session-based user identification.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User visits sagestocks.vercel.app       â”‚
â”‚ Landing page (index.html)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check for Active Session                â”‚
â”‚ â€¢ Cookie: encrypted session token       â”‚
â”‚ â€¢ If valid â†’ redirect to /analyze       â”‚
â”‚ â€¢ If invalid â†’ show "Sign in" button    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼ (No session)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Clicks "Sign in with Notion"       â”‚
â”‚ â†’ GET /api/auth/authorize               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Notion OAuth Flow                       â”‚
â”‚ 1. Redirect to Notion authorization URL â”‚
â”‚ 2. User grants workspace access         â”‚
â”‚ 3. Notion redirects back to /callback   â”‚
â”‚ 4. Exchange code for OAuth token        â”‚
â”‚ 5. Look up user in Beta Users DB        â”‚
â”‚ 6. Check approval status                â”‚
â”‚ 7. Create encrypted session token       â”‚
â”‚ 8. Set secure cookie                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Redirect Based on Status                â”‚
â”‚ â€¢ Approved â†’ /analyze.html              â”‚
â”‚ â€¢ Pending â†’ index.html (pending msg)    â”‚
â”‚ â€¢ Denied â†’ index.html (denied msg)      â”‚
â”‚ â€¢ New user â†’ Create in DB, set pending  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼ (Approved users only)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analyzer Page Loads (analyze.html)      â”‚
â”‚ â€¢ Ticker input field                    â”‚
â”‚ â€¢ "Analyze Stock" button                â”‚
â”‚ â€¢ userId from session (dynamic)         â”‚
â”‚ â€¢ Usage counter (user-specific quota)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User enters ticker (e.g., "AAPL")       â”‚
â”‚ and clicks "Analyze Stock"              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UI State â†’ "Analyzing..."               â”‚
â”‚ (spinner + status message)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
```

### Phase 2: Vercel Backend Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POST /api/analyze                       â”‚
â”‚ {                                       â”‚
â”‚   ticker: "AAPL",                       â”‚
â”‚   userId: "user://90089dd2..."          â”‚
â”‚ }                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Check Rate Limiting                  â”‚
â”‚ â€¢ Query Redis for user's daily count    â”‚
â”‚ â€¢ Admin bypass: userId == env.ADMIN_ID? â”‚
â”‚ â€¢ If limit exceeded â†’ return 429 error  â”‚
â”‚ Time: <500ms                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Fetch Current Market Data            â”‚
â”‚ (Parallel API calls)                    â”‚
â”‚                                         â”‚
â”‚ FMP API:                                â”‚
â”‚ â€¢ Daily price data (OHLC)               â”‚
â”‚ â€¢ Technical indicators (SMA, RSI, MACD) â”‚
â”‚ â€¢ Fundamental data (P/E, EPS, etc.)     â”‚
â”‚                                         â”‚
â”‚ FRED API:                               â”‚
â”‚ â€¢ Macro indicators (rates, GDP, etc.)   â”‚
â”‚                                         â”‚
â”‚ Time: ~3-5 seconds                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Calculate Scores                     â”‚
â”‚ â€¢ Technical Score (1.0-5.0)             â”‚
â”‚ â€¢ Fundamental Score (1.0-5.0)           â”‚
â”‚ â€¢ Macro Score (1.0-5.0)                 â”‚
â”‚ â€¢ Risk Score (1.0-5.0)                  â”‚
â”‚ â€¢ Sentiment Score (1.0-5.0)             â”‚
â”‚ â€¢ Sector Score (1.0-5.0)                â”‚
â”‚ â€¢ Composite Score (weighted average)    â”‚
â”‚ â€¢ Pattern Analysis                      â”‚
â”‚ â€¢ Recommendation (Buy/Hold/Sell)        â”‚
â”‚                                         â”‚
â”‚ Time: ~1 second                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
```

### Phase 3: Historical Context Retrieval

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Query Notion for Historical Data     â”‚
â”‚ (Parallel queries)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚
          â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query Stock      â”‚  â”‚ Query Stock      â”‚
â”‚ Analyses DB      â”‚  â”‚ History DB       â”‚
â”‚                  â”‚  â”‚                  â”‚
â”‚ Filter:          â”‚  â”‚ Filter:          â”‚
â”‚ Ticker = "AAPL"  â”‚  â”‚ Ticker = "AAPL"  â”‚
â”‚                  â”‚  â”‚ Sort: Date DESC  â”‚
â”‚ Returns:         â”‚  â”‚ Limit: 5         â”‚
â”‚ â€¢ Existing page? â”‚  â”‚                  â”‚
â”‚ â€¢ Previous scoresâ”‚  â”‚ Returns:         â”‚
â”‚ â€¢ Previous rec   â”‚  â”‚ â€¢ Last 5 entries â”‚
â”‚ â€¢ Last analysis  â”‚  â”‚ â€¢ With dates     â”‚
â”‚   date           â”‚  â”‚ â€¢ With scores    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Compute Deltas & Trends              â”‚
â”‚                                         â”‚
â”‚ IF previous analysis exists:            â”‚
â”‚ â€¢ Score changes: 3.8 â†’ 4.2 (+0.4)       â”‚
â”‚ â€¢ Recommendation change: Hold â†’ Buy     â”‚
â”‚ â€¢ Days since last analysis: 2 days      â”‚
â”‚                                         â”‚
â”‚ IF historical data exists:              â”‚
â”‚ â€¢ Trend direction: Improving â†—          â”‚
â”‚ â€¢ Score range: 3.5-4.2 (past 30 days)   â”‚
â”‚ â€¢ Average: 3.8                          â”‚
â”‚ â€¢ Volatility: Low/Medium/High           â”‚
â”‚                                         â”‚
â”‚ Time: ~2-5 seconds (Notion bottleneck)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
```

### Phase 4: AI Analysis Generation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Build Enriched Prompt for LLM        â”‚
â”‚                                         â”‚
â”‚ Context includes:                       â”‚
â”‚ â€¢ Current metrics (all scores)          â”‚
â”‚ â€¢ Previous analysis (if exists):        â”‚
â”‚   - Date, scores, recommendation        â”‚
â”‚   - Key metrics that changed            â”‚
â”‚ â€¢ Historical trend (past 5 analyses):   â”‚
â”‚   - Dates, scores, recommendations      â”‚
â”‚   - Trend direction                     â”‚
â”‚ â€¢ Computed deltas and insights          â”‚
â”‚                                         â”‚
â”‚ Prompt structure:                       â”‚
â”‚ "You are analyzing AAPL on Nov 1, 2025. â”‚
â”‚                                         â”‚
â”‚ Current metrics: [detailed data]        â”‚
â”‚                                         â”‚
â”‚ Previous analysis (Oct 30, 2025):       â”‚
â”‚ - Composite: 3.8 â†’ 4.2 (+0.4)           â”‚
â”‚ - Recommendation: Hold â†’ Buy            â”‚
â”‚ - Key changes: RSI 45â†’62, MACD crossoverâ”‚
â”‚                                         â”‚
â”‚ Historical trend (5 analyses):          â”‚
â”‚ - Steady improvement over 30 days       â”‚
â”‚ - Consistent Hold â†’ now upgraded to Buy â”‚
â”‚                                         â”‚
â”‚ Generate 7-section analysis:            â”‚
â”‚ 1. Data Foundation & Quality            â”‚
â”‚ 2. Dual-Lens (Value Ã— Momentum)         â”‚
â”‚ 3. Market Intelligence & Catalysts      â”‚
â”‚ 4. Strategic Trade Plan                 â”‚
â”‚ 5. Directional Outlook                  â”‚
â”‚ 6. Portfolio Integration                â”‚
â”‚ 7. Investment Recommendation            â”‚
â”‚                                         â”‚
â”‚ Highlight changes, trends, and          â”‚
â”‚ what triggered the upgrade."            â”‚
â”‚                                         â”‚
â”‚ NOTE: Prompt optimized for 50% token    â”‚
â”‚ reduction (information-dense format)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Call Google Gemini Flash 2.5 API     â”‚
â”‚                                         â”‚
â”‚ Input: ~1,500-2,500 tokens (50% less)   â”‚
â”‚ Output: ~1,250 tokens (50% less)        â”‚
â”‚                                         â”‚
â”‚ Receives:                               â”‚
â”‚ â€¢ Complete 7-section analysis           â”‚
â”‚ â€¢ Formatted in Notion markdown          â”‚
â”‚ â€¢ Includes H3 headings, bullets         â”‚
â”‚ â€¢ Highlights deltas and trends          â”‚
â”‚                                         â”‚
â”‚ Time: ~10-20 seconds                    â”‚
â”‚ Cost: ~$0.013 per analysis              â”‚
â”‚ (vs $0.026 with OpenAI GPT-4)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
```

### Phase 5: Notion Database Writes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Write to Stock Analyses Database     â”‚
â”‚                                         â”‚
â”‚ IF page exists (ticker found):          â”‚
â”‚ â€¢ Update existing page properties       â”‚
â”‚ â€¢ Update page content with new analysis â”‚
â”‚                                         â”‚
â”‚ IF page doesn't exist:                  â”‚
â”‚ â€¢ Create new database row/page          â”‚
â”‚ â€¢ Set all properties                    â”‚
â”‚ â€¢ Set page content                      â”‚
â”‚                                         â”‚
â”‚ Properties written:                     â”‚
â”‚ â€¢ All scores (Composite, Technical, etc)â”‚
â”‚ â€¢ Recommendation (Buy/Hold/Sell)        â”‚
â”‚ â€¢ Confidence level                      â”‚
â”‚ â€¢ Data quality grade                    â”‚
â”‚ â€¢ Analysis Date (with timestamp)        â”‚
â”‚ â€¢ Pattern scores & signals              â”‚
â”‚ â€¢ All technical metrics                 â”‚
â”‚ â€¢ All fundamental metrics               â”‚
â”‚                                         â”‚
â”‚ Content written:                        â”‚
â”‚ â€¢ Full 7-section analysis text          â”‚
â”‚                                         â”‚
â”‚ Returns: pageUrl of Stock Analyses page â”‚
â”‚                                         â”‚
â”‚ Time: ~2-3 seconds                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. Create Dated Child Analysis Page     â”‚
â”‚                                         â”‚
â”‚ Structure:                              â”‚
â”‚ Stock Analyses (Database)               â”‚
â”‚ â””â”€ AAPL (row/page from step 8)          â”‚
â”‚    â”œâ”€ AAPL Analysis - Nov 1, 2025 â† NEW â”‚
â”‚    â”œâ”€ AAPL Analysis - Oct 30, 2025      â”‚
â”‚    â””â”€ ...                               â”‚
â”‚                                         â”‚
â”‚ Page properties:                        â”‚
â”‚ â€¢ Title: "{Ticker} Analysis - {Date}"   â”‚
â”‚ â€¢ Parent: Stock Analyses AAPL page      â”‚
â”‚                                         â”‚
â”‚ Page content:                           â”‚
â”‚ â€¢ Copy of full 7-section analysis       â”‚
â”‚ â€¢ All metrics as properties             â”‚
â”‚ â€¢ Timestamp                             â”‚
â”‚                                         â”‚
â”‚ Returns: childPageUrl                   â”‚
â”‚                                         â”‚
â”‚ Time: ~2 seconds                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. Archive to Stock History Database   â”‚
â”‚                                         â”‚
â”‚ Create new entry:                       â”‚
â”‚ â€¢ Name: "AAPL - Nov 1, 2025 4:30 PM"    â”‚
â”‚ â€¢ Copy all metrics from analysis        â”‚
â”‚ â€¢ Copy full analysis content            â”‚
â”‚ â€¢ Set Content Status: "New"             â”‚
â”‚ â€¢ Link to Stock Analyses page           â”‚
â”‚                                         â”‚
â”‚ Purpose:                                â”‚
â”‚ â€¢ Time-series tracking                  â”‚
â”‚ â€¢ Trend analysis data source            â”‚
â”‚ â€¢ Historical reference                  â”‚
â”‚                                         â”‚
â”‚ Time: ~2 seconds                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 11. Increment Rate Limit Counter        â”‚
â”‚ â€¢ Update Redis: user's daily count + 1  â”‚
â”‚ Time: <500ms                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
```

### Phase 6: Response & User Notification

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 12. Return Success Response             â”‚
â”‚                                         â”‚
â”‚ {                                       â”‚
â”‚   success: true,                        â”‚
â”‚   ticker: "AAPL",                       â”‚
â”‚   pageUrl: "[child page URL]",          â”‚
â”‚   stockAnalysesUrl: "[main page URL]",  â”‚
â”‚   analysisDate: "2025-11-01T16:30:00Z", â”‚
â”‚   compositeScore: 4.2,                  â”‚
â”‚   recommendation: "Buy",                â”‚
â”‚   previousScore: 3.8,                   â”‚
â”‚   scoreChange: +0.4,                    â”‚
â”‚   rateLimit: {                          â”‚
â”‚     used: 5,                            â”‚
â”‚     limit: 10,                          â”‚
â”‚     remaining: 5                        â”‚
â”‚   }                                     â”‚
â”‚ }                                       â”‚
â”‚                                         â”‚
â”‚ Total time: ~18-25 seconds (target)     â”‚
â”‚ Actual (with Notion): ~35-50 seconds    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 13. Web Page Updates to Success State   â”‚
â”‚                                         â”‚
â”‚ UI displays:                            â”‚
â”‚ â€¢ Button: "âœ“ Analysis Complete" (green) â”‚
â”‚ â€¢ Status: "Analysis created in Notion"  â”‚
â”‚ â€¢ Score badge: "4.2/5.0 - Buy (+0.4)"   â”‚
â”‚ â€¢ Link: "View Results â†’"                â”‚
â”‚ â€¢ Secondary link: "Copy Link" button    â”‚
â”‚ â€¢ Usage counter: "5/10 analyses today"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 14. User Clicks "View Results â†’"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
```

### Phase 7: User Reviews Analysis in Notion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Notion Page Opens: AAPL Analysis        â”‚
â”‚                  Nov 1, 2025            â”‚
â”‚                                         â”‚
â”‚ User sees:                              â”‚
â”‚ â€¢ All metric properties in clean layout â”‚
â”‚ â€¢ Composite Score: 4.2/5.0              â”‚
â”‚ â€¢ Recommendation: Buy                   â”‚
â”‚ â€¢ Full 7-section analysis content:      â”‚
â”‚   1. Data Foundation & Quality          â”‚
â”‚      - Shows data completeness          â”‚
â”‚      - Previous: 3.8, Current: 4.2      â”‚
â”‚   2. Dual-Lens Analysis                 â”‚
â”‚      - Value vs Momentum perspective    â”‚
â”‚   3. Market Intelligence                â”‚
â”‚      - Recent news, catalysts           â”‚
â”‚   4. Strategic Trade Plan               â”‚
â”‚      - Entry/exit levels                â”‚
â”‚   5. Directional Outlook                â”‚
â”‚      - Trend improved over 30 days      â”‚
â”‚   6. Portfolio Integration              â”‚
â”‚      - Position sizing guidance         â”‚
â”‚   7. Investment Recommendation          â”‚
â”‚      - Upgraded from Hold to Buy        â”‚
â”‚      - Rationale with delta context     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User can also navigate to:              â”‚
â”‚                                         â”‚
â”‚ â€¢ Parent AAPL page (database row)       â”‚
â”‚   - See all historical child analyses   â”‚
â”‚   - Quick metrics reference             â”‚
â”‚                                         â”‚
â”‚ â€¢ Stock History database                â”‚
â”‚   - Time-series view of all analyses    â”‚
â”‚   - Trend charts (future feature)       â”‚
â”‚                                         â”‚
â”‚ â€¢ Stock Analyses database               â”‚
â”‚   - Compare across all tickers          â”‚
â”‚   - Portfolio overview                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Error Scenarios

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Error: Rate Limit Exceeded              â”‚
â”‚                                         â”‚
â”‚ Response:                               â”‚
â”‚ {                                       â”‚
â”‚   success: false,                       â”‚
â”‚   error: {                              â”‚
â”‚     code: "RATE_LIMIT_EXCEEDED",        â”‚
â”‚     message: "Rate limit exceeded"      â”‚
â”‚   },                                    â”‚
â”‚   rateLimit: {                          â”‚
â”‚     used: 10,                           â”‚
â”‚     limit: 10,                          â”‚
â”‚     remaining: 0,                       â”‚
â”‚     resetTime: "2025-11-02T07:00:00Z"   â”‚
â”‚   }                                     â”‚
â”‚ }                                       â”‚
â”‚                                         â”‚
â”‚ Web page displays:                      â”‚
â”‚ "Daily quota of 10 stock analyses       â”‚
â”‚  reached. Resets at midnight Pacific    â”‚
â”‚  Time. Upgrade to paid plan for         â”‚
â”‚  unlimited analyses."                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Error: API Timeout / Other Error        â”‚
â”‚                                         â”‚
â”‚ Response:                               â”‚
â”‚ {                                       â”‚
â”‚   success: false,                       â”‚
â”‚   error: {                              â”‚
â”‚     code: "ANALYSIS_FAILED",            â”‚
â”‚     message: "[specific error message]" â”‚
â”‚   }                                     â”‚
â”‚ }                                       â”‚
â”‚                                         â”‚
â”‚ Web page displays:                      â”‚
â”‚ "Error: [message]. Please try again."   â”‚
â”‚ Button re-enabled for retry             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### System Performance Summary

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Total Time Breakdown (v1.0.2 with Notion):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ Rate limit check: <500ms
â€¢ Fetch market data: 3-5 sec
â€¢ Calculate scores: 1 sec
â€¢ Query historical data (Notion): 2-5 sec â† BOTTLENECK
â€¢ Compute deltas: <1 sec
â€¢ LLM analysis generation: 10-20 sec
â€¢ Notion writes (3 operations): 6-10 sec â† BOTTLENECK
â€¢ Rate limit update: <500ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: 23-42 seconds (realistic with Notion)
TARGET: 18-25 seconds (achievable with PostgreSQL in v2.0)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Cost Per Analysis:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ FMP API calls: $0.001
â€¢ Google Gemini Flash 2.5: $0.013 (50% token reduction)
â€¢ Vercel compute: ~$0.001
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: ~$0.015 (~1.5Â¢) per analysis
(vs $0.028 with OpenAI GPT-4 - 47% savings)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Monthly Costs (10 beta users, 100 analyses/day):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ Vercel Pro: $20
â€¢ FMP API: $29
â€¢ Gemini API: $39 (3,000 analyses/month)
â€¢ Upstash Redis: $0 (free tier)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: $88/month (v1.0.2 with Notion)

Future (v2.0 with PostgreSQL):
â€¢ Vercel Pro: $20
â€¢ FMP API: $29
â€¢ Gemini API: $39
â€¢ Supabase: $0-25
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: $88-113/month
```

---

## Component Structure

### Directory Layout

```
stock-intelligence/
â”œâ”€â”€ api/                      # Vercel serverless function endpoints
â”‚   â”œâ”€â”€ analyze.ts            # Main analysis endpoint (390 LOC)
â”‚   â”œâ”€â”€ webhook.ts            # Notion archive webhook (180 LOC)
â”‚   â”œâ”€â”€ bypass.ts             # Bypass code activation (115 LOC)
â”‚   â”œâ”€â”€ usage.ts              # Usage tracking endpoint (115 LOC)
â”‚   â”œâ”€â”€ health.ts             # Health check endpoint (25 LOC)
â”‚   â”œâ”€â”€ cron/                 # Scheduled cron jobs
â”‚   â”‚   â””â”€â”€ scheduled-analyses.ts  # Daily analysis job (800s max duration)
â”‚   â””â”€â”€ jobs/                 # Background job endpoints
â”‚       â”œâ”€â”€ market-context.ts      # Daily market context job (120s max duration)
â”‚       â””â”€â”€ stock-events.ts        # Weekly stock events ingestion (300s max duration) [v1.2.16]
â”‚
â”œâ”€â”€ lib/                      # Core business logic libraries
â”‚   â”œâ”€â”€ orchestrator.ts       # Stock analysis orchestrator (522 LOC) [v1.0.5]
â”‚   â”œâ”€â”€ stock-analyzer.ts     # Pure analysis logic (315 LOC) [v1.0.5]
â”‚   â”œâ”€â”€ stock-events-ingestion.ts  # Event calendar ingestion (730 LOC) [v1.2.16]
â”‚   â”œâ”€â”€ rate-limiter.ts       # Rate limiting + bypass sessions (340 LOC)
â”‚   â”œâ”€â”€ scoring.ts            # Score calculation algorithms (850 LOC)
â”‚   â”œâ”€â”€ notion-client.ts      # Notion API wrapper (600 LOC)
â”‚   â”œâ”€â”€ fmp-client.ts         # FMP API client + event calendar (586 LOC) [v1.2.16]
â”‚   â”œâ”€â”€ fred-client.ts        # FRED API client (150 LOC)
â”‚   â”œâ”€â”€ errors.ts             # Custom error classes (180 LOC)
â”‚   â”œâ”€â”€ logger.ts             # Logging utilities (80 LOC)
â”‚   â”œâ”€â”€ validators.ts         # Input validation (120 LOC)
â”‚   â”œâ”€â”€ utils.ts              # Helper functions (100 LOC)
â”‚   â”œâ”€â”€ auth.ts               # Authentication helpers (60 LOC)
â”‚   â”œâ”€â”€ notion-poller.ts      # Notion polling logic (200 LOC)
â”‚   â””â”€â”€ market/               # Market context system [v1.0.7+]
â”‚       â”œâ”€â”€ context.ts        # Main market context API
â”‚       â”œâ”€â”€ data-collector.ts # FMP/FRED data fetching
â”‚       â”œâ”€â”€ regime-classifier.ts  # Risk-On/Off classification
â”‚       â”œâ”€â”€ cache.ts          # Redis caching (1-hour TTL)
â”‚       â””â”€â”€ types.ts          # Type definitions
â”‚
â”œâ”€â”€ config/                   # Configuration schemas
â”‚   â”œâ”€â”€ scoring-config.ts     # Scoring weights and thresholds
â”‚   â””â”€â”€ notion-schema.ts      # Database property mappings (8 databases) [v1.2.16]
â”‚
â”œâ”€â”€ scripts/                  # Testing and utility scripts
â”‚   â”œâ”€â”€ test-analyze.ts       # Local analysis testing (240 LOC)
â”‚   â”œâ”€â”€ test-notion-write.ts  # Notion write testing
â”‚   â”œâ”€â”€ test-stock-events.ts  # Stock events pipeline testing [v1.2.16]
â”‚   â””â”€â”€ poll-notion.ts        # Manual polling script
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ RATE_LIMITING_SETUP.md
â”‚   â”œâ”€â”€ USER_SETTINGS_PHASE1.md
â”‚   â”œâ”€â”€ PHASE1_QUICKSTART.md
â”‚   â”œâ”€â”€ NOTION_DATABASE_TEMPLATE.md
â”‚   â””â”€â”€ PHASE1_WEBHOOK_UPDATE.md
â”‚
â”œâ”€â”€ vercel.json               # Vercel configuration (CORS, timeouts)
â”œâ”€â”€ package.json              # Dependencies and scripts
â”œâ”€â”€ tsconfig.json             # TypeScript configuration
â”œâ”€â”€ .env.v1.example           # Environment variable template
â””â”€â”€ SETUP.md                  # Setup and deployment guide
```

### Core Components

#### 1. API Layer (`/api`)
**Purpose:** Serverless function endpoints exposed via Vercel

**Key Files:**
- `analyze.ts` - Main analysis orchestrator
  - Validates input
  - Checks rate limits
  - Fetches financial data
  - Calculates scores
  - Writes to Notion
  - Returns results + rate limit info

- `webhook.ts` - Notion automation trigger for archiving
  - Receives page data from Notion
  - Moves analysis to Stock History database
  - Updates status flags

- `bypass.ts` - Bypass code activation
  - Accepts URL params or JSON body
  - Validates bypass code
  - Creates Redis session (expires midnight UTC)

- `usage.ts` - Usage tracking (no quota consumption)
  - Returns current usage count
  - Shows remaining analyses
  - Indicates bypass status

#### 2. Business Logic Layer (`/lib`)
**Purpose:** Reusable, testable business logic

**Key Files:**

- `orchestrator.ts` - **Stock Analysis Orchestrator (v1.0.5)** â­
  - Eliminates redundant API calls across multiple users
  - Deduplication: Analyzes each ticker once, broadcasts to all subscribers
  - Priority queue: Pro > Analyst > Starter > Free
  - Rate limiting: Configurable delay between tickers (default 8s)
  - Fault isolation: One failure doesn't block others
  - Retry logic: Exponential backoff on Gemini 503 errors
  - Dry-run mode: Test without API calls
  - **Impact:** 99.9% cost reduction at scale ($4,745/year â†’ $4.75/year)
  - See [ORCHESTRATOR.md](ORCHESTRATOR.md) for details

- `stock-analyzer.ts` - **Pure Analysis Logic (v1.0.5)** â­
  - Extracted from `api/analyze.ts` for reusability
  - `analyzeStockCore()`: Fetches data, calculates scores, generates LLM analysis
  - `validateAnalysisComplete()`: Ensures all required fields populated
  - No HTTP/auth concerns - pure business logic
  - Shared by HTTP endpoint and orchestrator

- `stock-events-ingestion.ts` - **Stock Events Pipeline (v1.2.16)** â­
  - Fetches upcoming stock events from FMP (earnings, dividends, splits)
  - Deduplication pattern: Fetches each ticker once, distributes to all owners
  - Database discovery: Auto-finds Stock Events database in each user's workspace
  - Upsert logic: Creates if new, updates if exists (by ticker + event_type + date)
  - Graceful error handling: Logs warnings, continues processing (no cascade failures)
  - Runs weekly via cron (Sundays 12:00 UTC) for next 90 days of events
  - **Impact:** 99% API savings at scale (100 users sharing stocks)
  - See [CHANGELOG.md#v1.2.16](CHANGELOG.md) for full details

- `rate-limiter.ts` - Rate limiting engine
  - Redis key management (`rate_limit:{userId}:{date}`)
  - Bypass session management (`bypass_session:{userId}`)
  - TTL-based expiry (automatic midnight UTC reset)
  - Graceful degradation on Redis failure

- `scoring.ts` - Scoring algorithms
  - Technical score calculation (0-100)
  - Fundamental score calculation (0-100)
  - Composite score weighting
  - Pattern matching logic

- `notion-client.ts` - Notion API wrapper
  - Page read operations
  - Property updates (batch writes)
  - AI prompt execution
  - Database queries

- `fmp-client.ts` - Financial data fetching
  - Real-time quotes
  - Financial statements
  - Technical indicators
  - Profile/company info
  - **Event calendars (v1.2.16):** Earnings, dividends, stock splits, economic events

- `fred-client.ts` - Macro data fetching
  - Yield curve (DGS10, DGS2)
  - VIX volatility index
  - Economic indicators

- `errors.ts` - Custom error classes
  - `SageStocksError` (base class)
  - `RateLimitError` (429 status)
  - `ValidationError` (400 status)
  - `NotionError` (Notion API failures)
  - User-friendly error messages

#### 3. Configuration Layer (`/config`)
**Purpose:** Centralized configuration schemas

- `scoring-config.ts` - Scoring weights, thresholds, boundaries
- `notion-schema.ts` - Database property name mappings

---

## Data Flow

### Primary Analysis Flow

```
1. User Action (Notion)
   â””â”€â–¶ Set "Request Analysis" = true in Stock Analyses database

2. Notion Automation
   â””â”€â–¶ Trigger webhook: POST /api/webhook
       Body: { ticker, pageId, userId, ... }

3. Rate Limit Check
   â””â”€â–¶ RateLimiter.checkAndIncrement(userId)
       â”œâ”€â–¶ Check bypass session (Redis)
       â”œâ”€â–¶ Check current count (Redis)
       â””â”€â–¶ Allow or reject (429 error)

4. Data Fetching (Parallel)
   â”œâ”€â–¶ FMP Client: Quote, financials, technicals
   â”œâ”€â–¶ FRED Client: Macro indicators
   â””â”€â–¶ Wait for all responses

5. Score Calculation
   â”œâ”€â–¶ Calculate technical score (0-100)
   â”œâ”€â–¶ Calculate fundamental score (0-100)
   â”œâ”€â–¶ Calculate composite score (weighted)
   â””â”€â–¶ Detect patterns (breakout, reversal, etc.)

6. Notion Write
   â”œâ”€â–¶ Update page properties (batch write)
   â”œâ”€â–¶ Trigger AI analysis prompt
   â””â”€â–¶ Set "Request Analysis" = false

7. Response
   â””â”€â–¶ Return JSON with scores + rate limit info
```

### Orchestrator Flow (v1.0.5) â­

**Purpose:** Eliminate redundant API calls by analyzing each ticker once and broadcasting to all subscribers.

**Trigger:** Daily cron job at 6am PT via Vercel Cron

```
1. Cron Trigger
   â””â”€â–¶ POST /api/cron/scheduled-analyses
       Headers: { Authorization: Bearer CRON_SECRET }

2. Request Collection (collectStockRequests)
   â”œâ”€â–¶ Get all beta users from database
   â”œâ”€â–¶ For each user:
   â”‚   â”œâ”€â–¶ Decrypt OAuth token
   â”‚   â”œâ”€â–¶ Query Stock Analyses DB (filter: Analysis Cadence = "Daily")
   â”‚   â””â”€â–¶ Extract ticker + subscriber info
   â””â”€â–¶ Build deduplicated map: {ticker â†’ [subscriber1, subscriber2, ...]}

3. Priority Queue Building (buildPriorityQueue)
   â”œâ”€â–¶ For each ticker, find highest subscriber tier:
   â”‚   Pro (1) > Analyst (2) > Starter (3) > Free (4)
   â”œâ”€â–¶ Sort queue by priority (ascending)
   â””â”€â–¶ Return ordered queue: [{ticker, priority, subscribers}, ...]

4. Queue Processing (processQueue)
   â””â”€â–¶ For each ticker in queue:
       â”‚
       â”œâ”€â–¶ 4a. Analyze with Retry (analyzeWithRetry)
       â”‚   â”œâ”€â–¶ Call analyzeStockCore() once
       â”‚   â”œâ”€â–¶ On Gemini 503: retry with backoff (2s, 4s, 8s)
       â”‚   â””â”€â–¶ Return analysis result
       â”‚
       â”œâ”€â–¶ 4b. Validate Completeness (validateAnalysisComplete)
       â”‚   â”œâ”€â–¶ Check success flag
       â”‚   â”œâ”€â–¶ Check scores > 0
       â”‚   â”œâ”€â–¶ Check LLM content exists
       â”‚   â””â”€â–¶ Proceed only if complete
       â”‚
       â”œâ”€â–¶ 4c. Broadcast to Subscribers (broadcastToSubscribers)
       â”‚   â”œâ”€â–¶ Promise.allSettled([...]) - parallel with fault isolation
       â”‚   â”œâ”€â–¶ For each subscriber:
       â”‚   â”‚   â”œâ”€â–¶ broadcastToUser() with retry (5s backoff)
       â”‚   â”‚   â”œâ”€â–¶ Write to Stock Analyses DB
       â”‚   â”‚   â””â”€â–¶ Write to Stock History DB
       â”‚   â””â”€â–¶ Log success/failure per user
       â”‚
       â””â”€â–¶ 4d. Rate Limit Delay
           â””â”€â–¶ Wait ANALYSIS_DELAY_MS (default: 8000ms)
               Skip delay after last ticker

5. Metrics Collection
   â”œâ”€â–¶ totalTickers: Unique stocks analyzed
   â”œâ”€â–¶ totalSubscribers: Total users subscribed
   â”œâ”€â–¶ analyzed/failed: Success/failure counts
   â”œâ”€â–¶ broadcasts: Total/successful/failed
   â”œâ”€â–¶ apiCallsSaved: (subscribers - 1) Ã— 17 calls per ticker
   â””â”€â–¶ durationMs: Total execution time

6. Response
   â””â”€â–¶ Return JSON with comprehensive metrics
```

**Key Benefits:**
- **Deduplication:** 1 analysis â†’ N subscribers (99.9% API reduction at scale)
- **Priority-Based:** Premium users' stocks analyzed first
- **Fault Isolation:** One failure doesn't block others (Promise.allSettled)
- **Rate Limiting:** Configurable delay prevents API overload
- **Retry Logic:** Exponential backoff on transient errors
- **Dry-Run Mode:** Test logic without API calls (ORCHESTRATOR_DRY_RUN=true)

**Configuration:**
- `ANALYSIS_DELAY_MS`: Delay between tickers (default: 8000ms)
- `ORCHESTRATOR_DRY_RUN`: Test mode without API calls (default: false)

**See:** [ORCHESTRATOR.md](ORCHESTRATOR.md) for complete documentation

### Bypass Code Flow

```
1. User Input
   â””â”€â–¶ GET /api/bypass?userId=XXX&code=YYY
       (Or POST with JSON body)

2. Code Validation
   â”œâ”€â–¶ Extract code from URL params or body
   â”œâ”€â–¶ Compare to env var (RATE_LIMIT_BYPASS_CODE)
   â””â”€â–¶ Accept or reject

3. Session Creation
   â””â”€â–¶ Redis SET bypass_session:{userId} = "1"
       EXPIREAT = next_midnight_UTC

4. Future Requests
   â””â”€â–¶ RateLimiter checks session first
       If exists â†’ unlimited access
       If expired â†’ normal rate limiting
```

### Usage Check Flow

```
1. User Request
   â””â”€â–¶ GET /api/usage?userId=XXX

2. Bypass Check
   â”œâ”€â–¶ Check Redis for active session
   â””â”€â–¶ If bypassed â†’ return { remaining: 999 }

3. Normal Count
   â”œâ”€â–¶ GET rate_limit:{userId}:{date}
   â””â”€â–¶ Return { used: N, remaining: 10-N }

4. Response
   â””â”€â–¶ JSON with usage data (no quota consumed)
```

---

## API Endpoints

### `/api/analyze` (POST)
**Purpose:** Execute stock analysis and return results (requires authentication)

**Authentication:** Session token in cookie (encrypted, from Notion OAuth)

**Request:**
```json
{
  "ticker": "AAPL",
  "userId": "user-notion-page-id-from-session"
}
```

**Headers:**
```
Cookie: session=<encrypted-session-token>
```

**Response (200):**
```json
{
  "success": true,
  "ticker": "AAPL",
  "compositeScore": 72.5,
  "technicalScore": 68.0,
  "fundamentalScore": 77.0,
  "recommendation": "HOLD",
  "pattern": "CONSOLIDATION",
  "metrics": { /* full data object */ },
  "rateLimit": {
    "remaining": 7,
    "total": 10,
    "resetAt": "2025-11-01T00:00:00.000Z",
    "bypassed": false
  }
}
```

**Response (429 - Rate Limit):**
```json
{
  "success": false,
  "error": {
    "code": "USER_RATE_LIMIT_EXCEEDED",
    "message": "Daily analysis limit reached. Your limit will reset at Oct 31, 11:59 PM PT.",
    "statusCode": 429
  }
}
```

**Headers:**
- `X-RateLimit-Remaining` - Analyses remaining
- `X-RateLimit-Total` - Total daily limit
- `X-RateLimit-Reset` - ISO 8601 reset timestamp

**Configuration:**
- Timeout: 300 seconds (5 minutes)
- CORS: Enabled (all origins)

---

### `/api/bypass` (GET/POST)
**Purpose:** Activate bypass code for unlimited analyses

**Method 1: URL Parameters (GET)**
```bash
GET /api/bypass?userId=user-123&code=secret-bypass-code
```

**Method 2: JSON Body (POST)**
```json
POST /api/bypass
{
  "userId": "user-123",
  "code": "secret-bypass-code"
}
```

**Response (200):**
```json
{
  "success": true,
  "message": "Bypass code activated successfully",
  "expiresAt": "2025-11-01T00:00:00.000Z"
}
```

**Response (400 - Invalid Code):**
```json
{
  "success": false,
  "error": "Invalid bypass code"
}
```

**Configuration:**
- Timeout: 60 seconds (default)
- Session expires: Midnight UTC

---

### `/api/setup` (GET/POST)
**Purpose:** First-time user onboarding - auto-detect or manually configure user's Notion databases

**Why This Exists:** When users duplicate the Sage Stocks template, Notion creates brand new database IDs unique to their workspace. The backend needs to discover and store these IDs to know where to write analysis results for each user. This is the foundation of the multi-user SaaS architecture.

#### GET - Auto-Detection
**Authentication:** Session token in cookie (encrypted, from Notion OAuth)

**Request:**
```bash
GET /api/setup
```

**Response (200 - Not Yet Setup):**
```json
{
  "alreadySetup": false,
  "detection": {
    "stockAnalysesDb": {
      "id": "abc123...",
      "title": "Stock Analyses",
      "score": 0.85,
      "confidence": "high"
    },
    "stockHistoryDb": {
      "id": "def456...",
      "title": "Stock History",
      "score": 0.87,
      "confidence": "high"
    },
    "sageStocksPage": {
      "id": "ghi789...",
      "title": "Sage Stocks",
      "url": "https://notion.so/...",
      "score": 1.0,
      "confidence": "high"
    }
  },
  "needsManual": false
}
```

**Response (200 - Already Setup):**
```json
{
  "alreadySetup": true,
  "redirect": "/analyze"
}
```

**Response (200 - Partial Detection, Manual Fallback Needed):**
```json
{
  "alreadySetup": false,
  "detection": {
    "stockAnalysesDb": { /* found */ },
    "stockHistoryDb": null,  // Not found
    "sageStocksPage": { /* found */ }
  },
  "needsManual": true
}
```

**How Auto-Detection Works:**

1. **Search User's Workspace** (via their OAuth token)
   - Queries all databases using Notion search API
   - Queries all pages using Notion search API
   - Returns 100+ databases/pages typically

2. **Scoring Algorithm** (`lib/template-detection.ts`)
   - **Title Matching** (30% weight): "Stock Analyses", "Stock History", etc.
   - **Required Properties** (50% weight): Must have all required props (e.g., Ticker, Composite Score, Recommendation)
   - **Optional Properties** (20% weight): Bonus points for having optional props
   - **Property Types**: Small bonus for correct types (number, select, date, etc.)

3. **Confidence Levels**
   - **High** (>0.8): Title + all required props + most optional props match
   - **Medium** (0.6-0.8): Title or props match, but not perfect
   - **Low** (0.5-0.6): Minimal match, might be wrong database
   - **Failed** (<0.5): Rejected, not shown to user

4. **Threshold**: Databases must score â‰¥0.5 to be considered a match

**Criteria for Stock Analyses:**
```typescript
{
  titleMatches: ['Stock Analyses', 'Analyses', 'Stock Analysis'],
  requiredProps: ['Ticker', 'Composite Score', 'Recommendation'],
  optionalProps: ['Technical Score', 'Fundamental Score', 'Analysis Date', 'Current Price', 'Status']
}
```

**Criteria for Stock History:**
```typescript
{
  titleMatches: ['Stock History', 'History', 'Price History'],
  requiredProps: ['Ticker', 'Analysis Date', 'Current Price'],
  optionalProps: ['Technical Score', 'Composite Score', 'Volume', 'Recommendation']
}
```

#### POST - Confirm Setup (Auto or Manual)
**Purpose:** Save detected or manually-provided database IDs to Beta Users database

**Request:**
```json
{
  "stockAnalysesDbId": "abc123...",
  "stockHistoryDbId": "def456...",
  "sageStocksPageId": "ghi789..."
}
```

**Validation:** Backend verifies:
1. âœ… Can read from Stock Analyses database (via user's OAuth token)
2. âœ… Can write to Stock Analyses database (test query)
3. âœ… Can read from Stock History database
4. âœ… Can read from Sage Stocks page
5. âŒ Returns detailed errors if any validation fails

**Response (200 - Success):**
```json
{
  "success": true,
  "redirect": "/analyze",
  "message": "Setup completed successfully!"
}
```

**Response (400 - Validation Failed):**
```json
{
  "success": false,
  "errors": [
    {
      "field": "stockAnalysesDbId",
      "message": "Cannot access Stock Analyses database. Make sure your Notion integration has access to this database.",
      "helpUrl": "https://docs.notion.com/reference/intro#integrations"
    }
  ]
}
```

**What Gets Stored in Beta Users Database:**
```typescript
{
  "Stock Analyses DB ID": "abc123...",
  "Stock History DB ID": "def456...",
  "Sage Stocks Page ID": "ghi789...",
  "Template Version": "1.0.0",
  "Setup Completed At": "2025-11-11T20:00:00.000Z"
}
```

**Configuration:**
- Timeout: 60 seconds (default)
- Auto-detection searches up to 1000 databases/pages (10 batches of 100)

---

### `/api/debug-reset-setup` (POST)
**Purpose:** [DEBUG ONLY] Clear user's stored database IDs to enable re-testing of setup flow

**Authentication:** Session token in cookie (encrypted, from Notion OAuth)

**Request:**
```bash
POST /api/debug-reset-setup
```

**Response (200):**
```json
{
  "success": true,
  "message": "Setup reset successfully - you can now test auto-detection again"
}
```

**What It Clears:**
- Stock Analyses DB ID â†’ empty
- Stock History DB ID â†’ empty
- Sage Stocks Page ID â†’ empty
- Template Version â†’ empty
- Setup Completed At â†’ null

**Note:** This is a temporary debugging endpoint added in v1.1.7. Can be removed after Cohort 1 is stable.

**Configuration:**
- Timeout: 60 seconds (default)

---

### `/api/debug/market-context` (GET)
**Purpose:** [DIAGNOSTICS] Display current market context status, cache health, and API connectivity

**Added:** v1.0.8b - For debugging market context availability issues

**Authentication:** None (public diagnostic endpoint)

**Request:**
```bash
GET /api/debug/market-context
```

**Response (200 - All Systems Operational):**
```json
{
  "timestamp": "2025-11-18T05:47:09.167Z",
  "environment": {
    "variables": {
      "FMP_API_KEY": true,
      "FRED_API_KEY": true,
      "UPSTASH_REDIS_REST_URL": true,
      "UPSTASH_REDIS_REST_TOKEN": true
    },
    "allConfigured": true
  },
  "cache": {
    "metadata": {
      "exists": true,
      "age": 10314,
      "ttl": 3590
    },
    "hasCached": true,
    "cachedRegime": "Transition",
    "cachedTimestamp": "2025-11-18T05:50:38.950Z"
  },
  "fresh": {
    "success": true,
    "regime": "Transition",
    "regimeConfidence": 0.5785714285714286,
    "vix": 19.83,
    "spy": {
      "symbol": "SPY",
      "price": 665.67,
      "change1D": -0.93164,
      "change5D": 0,
      "change1M": 0,
      "ma50": 668.4784,
      "ma200": 613.1523
    }
  }
}
```

**Response (500 - Market Context Fetch Failed):**
```json
{
  "timestamp": "2025-11-18T05:47:09.167Z",
  "environment": {
    "variables": { /* ... */ },
    "allConfigured": true
  },
  "cache": {
    "metadata": { "exists": false },
    "hasCached": false
  },
  "fresh": {
    "success": false,
    "error": {
      "message": "Request failed with status code 429",
      "name": "AxiosError",
      "stack": ["Error: Request failed...", "at createError...", "at settle..."]
    }
  }
}
```

**What It Shows:**
- **Environment Variables:** Which API keys and Redis credentials are configured
- **Cache Metadata:** Whether cache exists, age in milliseconds, TTL in seconds
- **Cached Data:** Current cached regime, timestamp (if cache hit)
- **Fresh Fetch:** Attempts to fetch fresh market context and reports success/error
- **Market Data:** Current market regime, VIX level, SPY performance

**Common Diagnostics:**

| Condition | Meaning | Action |
|-----------|---------|--------|
| `cache.ttl: -1` | Cache expired but not deleted | Normal (Redis garbage collection pending) |
| `cache.ttl: 3600` | Fresh cache (1 hour TTL) | Optimal state |
| `cache.hasCached: false` | No valid cached data | Fresh fetch will occur on next analysis |
| `fresh.success: false` | API fetch failed | Check error message for rate limit (429) or timeout |
| `environment.allConfigured: false` | Missing API keys | Check Vercel environment variables |

**Redis Cache Implementation Details:**
- **Cache Key:** `market:context:v1`
- **TTL:** 3600 seconds (1 hour)
- **Format:** Direct JSON of MarketContext object
- **Upstash API:** Uses `?EX=3600` query parameter (not JSON body)
- **Expiration Check:** Validates `ttl > 0` before returning cached data
- **Fallback:** Returns neutral market context if fetch fails

**Note:** This endpoint always performs a **force refresh** (bypasses cache for fetch test), so it will always show the result of attempting a fresh API call. The cache metadata reflects the state before the forced refresh.

**Production URL:**
```
https://sagestocks.vercel.app/api/debug/market-context
```

**Configuration:**
- Timeout: 60 seconds (default)
- Public access (no authentication required)

---

### `/api/usage` (GET)
**Purpose:** Check current usage without consuming quota

**Request:**
```bash
GET /api/usage?userId=user-123
```

**Response (200):**
```json
{
  "success": true,
  "usage": {
    "used": 3,
    "remaining": 7,
    "total": 10,
    "resetAt": "2025-11-01T00:00:00.000Z",
    "bypassed": false
  }
}
```

**Response (Bypassed):**
```json
{
  "success": true,
  "usage": {
    "used": 0,
    "remaining": 999,
    "total": 10,
    "resetAt": "2025-11-01T00:00:00.000Z",
    "bypassed": true
  }
}
```

---

### `/api/webhook` (POST)
**Purpose:** Notion automation trigger for archiving

**Request:**
```json
{
  "ticker": "AAPL",
  "pageId": "notion-page-id-xyz",
  "action": "archive"
}
```

**Response (200):**
```json
{
  "success": true,
  "message": "Page archived successfully"
}
```

**Configuration:**
- Timeout: 60 seconds
- Called by: Notion automation ("Send to History" button)

---

### `/api/health` (GET)
**Purpose:** Health check and API information

**Response (200):**
```json
{
  "status": "ok",
  "version": "1.0.0-beta.1",
  "timestamp": "2025-11-09T10:00:00.000Z",
  "environment": "production",
  "auth": {
    "enabled": true,
    "method": "Notion OAuth (session-based)"
  },
  "endpoints": [
    {
      "path": "/api/analyze",
      "method": "POST",
      "description": "Analyze a stock and sync to Notion",
      "requiresAuth": true
    },
    {
      "path": "/api/auth/authorize",
      "method": "GET",
      "description": "Initiate Notion OAuth flow",
      "requiresAuth": false
    }
  ],
  "config": {
    "timeouts": {
      "analyze": 300,
      "webhook": 60,
      "default": 30
    }
  }
}
```

**Configuration:**
- Timeout: 10 seconds
- No authentication required

---

### `/api/auth/authorize` (GET)
**Purpose:** Initiate Notion OAuth flow with template duplication prevention (v1.1.1, enhanced v1.2.5)

**Query Parameters:**
- `existing_user` (optional) - Set to `"true"` by frontend if user has existing session/setup

**Response:** HTTP 302 redirect to Notion authorization URL

**Template Duplication Prevention (v1.2.5):**

Prevents duplicate "Sage Stocks" templates when users re-authenticate (e.g., after API upgrades, session expiry). Uses a **3-layer detection system**:

| Layer | Detection Method | When It Works | Status Logged |
|-------|-----------------|---------------|---------------|
| **1. URL Parameter** | Frontend passes `?existing_user=true` based on localStorage or cookie | User has `sage_stocks_setup_complete` flag OR session cookie | `existing_via_param` |
| **2. Expired Cookie** | Session cookie exists but Redis session expired | Common during re-authentication after 24-hour TTL | `expired_session_cookie` |
| **3. Valid Session** | Active Redis session with completed setup | User has valid session and database IDs configured | `setup_complete` |

**Decision Flow:**
```typescript
// Layer 1: Frontend detection
if (req.query.existing_user === 'true') â†’ Skip template_id

// Layer 2: Cookie presence (even if expired)
else if (hasSessionCookie && sessionExpired) â†’ Skip template_id  // Conservative approach

// Layer 3: Valid session check
else if (validSession && setupComplete) â†’ Skip template_id

// Default: New user
else â†’ Include template_id in OAuth URL
```

**Why Layer 2 is Critical:**
- When users re-authenticate after session expiry, Redis no longer has their session data
- Previous fix (v1.2.4) only checked valid sessions, which failed for expired sessions
- Layer 2 detects cookie **presence** (not validity) and assumes returning user
- Conservative approach: Better to skip template for edge-case new users than duplicate for existing users

**Logging:**
All detections are logged with `detectionMethod` field for debugging:
- `url_parameter` - Frontend detected existing user
- `expired_cookie` - Cookie exists but Redis session expired
- `valid_session` - Active session with setup complete
- `no_cookie` - New user (no cookie detected)
- `error` - Detection failed, defaulting to new user

---

### `/api/auth/callback` (GET)
**Purpose:** Handle OAuth callback from Notion (v1.1.1)

**Query Parameters:**
- `code` - OAuth authorization code from Notion
- `state` - CSRF protection token

**Response:** HTTP 302 redirect to appropriate page based on user status

---

### `/api/auth/session` (GET)
**Purpose:** Check current session status (v1.1.1)

**Response:**
```json
{
  "authenticated": true,
  "userId": "notion-page-id",
  "status": "approved",
  "email": "user@example.com"
}
```

---

### `/api/setup` (GET/POST)
**Purpose:** Template setup and auto-detection (v1.1.6)

**GET Response:**
```json
{
  "detected": {
    "stockAnalysesDb": {
      "id": "db-id",
      "title": "Stock Analyses",
      "confidence": 0.95
    },
    "stockHistoryDb": {
      "id": "db-id",
      "title": "Stock History",
      "confidence": 0.90
    },
    "sageStocksPage": {
      "id": "page-id",
      "title": "Sage Stocks",
      "confidence": 0.85
    }
  }
}
```

**POST Body:**
```json
{
  "stockAnalysesDbId": "validated-db-id",
  "stockHistoryDbId": "validated-db-id",
  "sageStocksPageId": "validated-page-id"
}
```

---

### `/api/upgrade` (POST)
**Purpose:** Template version upgrade (v1.1.6)

**Request:**
```json
{
  "targetVersion": "0.1.0",
  "confirmDataSafety": true
}
```

**Response:**
```json
{
  "success": true,
  "upgradedFrom": "1.0.0",
  "upgradedTo": "0.1.0",
  "changesApplied": [
    "Added Market Intelligence database",
    "Updated Stock Analyses schema",
    "Added template version tracking"
  ],
  "timestamp": "2025-11-09T10:00:00.000Z"
}
```

---

## External Integrations

### 1. Upstash Redis
**Purpose:** Distributed state for rate limiting

**Connection:**
- REST API (no TCP connections)
- Endpoint: `UPSTASH_REDIS_REST_URL`
- Auth: Bearer token (`UPSTASH_REDIS_REST_TOKEN`)

**Data Stored:**
- Rate limit counters: `rate_limit:{userId}:{YYYY-MM-DD}`
- Bypass sessions: `bypass_session:{userId}`

**Commands Used:**
- `GET` - Retrieve count/session
- `INCR` - Increment counter
- `EXPIREAT` - Set TTL to midnight UTC
- `SET` + `EXPIREAT` - Create session with expiry

**Free Tier Limits:**
- 10,000 commands per day
- 256 MB storage
- Automatic eviction (LRU)

**Failure Handling:**
- Graceful degradation (fails open)
- Logs error but allows request
- No Redis = no rate limiting (intentional)

---

### 2. Financial Modeling Prep (FMP)
**Purpose:** Stock data provider

**Endpoint:** `https://financialmodelingprep.com/api/v3/`

**Data Fetched:**
- Real-time quotes (`/quote/{ticker}`)
- Financial statements (`/income-statement/{ticker}`)
- Balance sheets (`/balance-sheet-statement/{ticker}`)
- Technical indicators (`/technical_indicator/daily/{ticker}`)
- Company profile (`/profile/{ticker}`)

**Pricing:**
- Starter: $22/month
- Professional: $29/month (current plan)

**Rate Limits:**
- 250 requests per minute
- 10,000 requests per day

**Error Handling:**
- Retry with exponential backoff
- Custom `APIResponseError` class
- Logs all API failures

---

### 3. FRED API (Federal Reserve Economic Data)
**Purpose:** Macroeconomic indicators

**Endpoint:** `https://api.stlouisfed.org/fred/series/observations`

**Data Fetched:**
- 10-Year Treasury Yield (`DGS10`)
- 2-Year Treasury Yield (`DGS2`)
- VIX Volatility Index (`VIXCLS`)
- Unemployment Rate (`UNRATE`)

**Pricing:** Free (public API)

**Rate Limits:**
- 120 requests per minute
- No daily limit

**Error Handling:**
- Falls back gracefully on failure
- Macros are optional for analysis

---

### 4. Notion API
**Purpose:** Database integration and UI

**Connection:**
- Official SDK: `@notionhq/client`
- Auth: Integration token (`NOTION_API_TOKEN`)

**Operations:**
- Read pages (`pages.retrieve`)
- Update properties (`pages.update`)
- Query databases (`databases.query`)
- Execute AI prompts (via page comments)

**Databases Used:**
- **Stock Analyses** - Active analysis workspace
  - Ticker (title)
  - Request Analysis (checkbox)
  - Composite Score (number)
  - Technical Score (number)
  - Fundamental Score (number)
  - Recommendation (select)
  - Pattern (select)
  - Last Updated (date)
  - Content Status (select)

- **Stock History** - Archive of past analyses
  - Same schema as Stock Analyses
  - Read-only for user

**Rate Limits:**
- 3 requests per second (per integration)
- Retry-After header respected

**Error Handling:**
- Exponential backoff on 429 errors
- Custom `NotionError` class
- Detailed logging

---

## Rate Limiting Architecture

### Design Goals
1. **User-level quotas** - 10 analyses per user per day
2. **Distributed state** - Works across serverless instances
3. **Automatic reset** - Midnight UTC daily reset
4. **Bypass mechanism** - Session-based unlimited access
5. **Graceful degradation** - Fails open if Redis unavailable

### Implementation

#### Redis Key Schema
```
rate_limit:{userId}:{YYYY-MM-DD}     # Daily counter
  - Value: Integer (0-10)
  - TTL: Expires at midnight UTC
  - Commands: INCR, GET, EXPIREAT

bypass_session:{userId}              # Bypass session
  - Value: "1" (existence check only)
  - TTL: Expires at midnight UTC
  - Commands: SET, GET, EXPIREAT
```

#### Rate Limit Check Algorithm
```typescript
async checkAndIncrement(userId: string): Promise<RateLimitResult> {
  // Priority 1: Check for active bypass session
  if (await hasActiveBypass(userId)) {
    return { allowed: true, remaining: 999, bypassed: true };
  }

  // Priority 2: Check if rate limiting is disabled (dev mode)
  if (!this.enabled) {
    return { allowed: true, remaining: 999, bypassed: false };
  }

  // Priority 3: Normal rate limiting
  const key = getRateLimitKey(userId);  // rate_limit:user-123:2025-10-31
  const count = await getCount(key);     // GET from Redis

  if (count >= maxAnalyses) {
    return { allowed: false, remaining: 0 };
  }

  // Increment counter and set expiry
  await increment(key, resetAt);         // INCR + EXPIREAT
  return { allowed: true, remaining: maxAnalyses - (count + 1) };
}
```

#### Bypass Code Activation
```typescript
async activateBypass(userId: string, code: string): Promise<boolean> {
  // Validate code against environment variable
  if (code !== process.env.RATE_LIMIT_BYPASS_CODE) {
    return false;
  }

  // Create session with expiry at midnight UTC
  const key = `bypass_session:${userId}`;
  const midnight = getNextMidnightUTC();

  await redis.set(key, "1");
  await redis.expireat(key, Math.floor(midnight.getTime() / 1000));

  return true;
}
```

#### Midnight UTC Reset
```typescript
function getNextMidnightUTC(): Date {
  const now = new Date();
  const tomorrow = new Date(
    Date.UTC(
      now.getUTCFullYear(),
      now.getUTCMonth(),
      now.getUTCDate() + 1,
      0, 0, 0, 0
    )
  );
  return tomorrow;
}
```

### Configuration
```bash
# Enable/disable rate limiting
RATE_LIMIT_ENABLED=true

# Daily quota per user
RATE_LIMIT_MAX_ANALYSES=10

# Bypass code (change to revoke all sessions)
RATE_LIMIT_BYPASS_CODE=your-secret-code

# Upstash Redis connection
UPSTASH_REDIS_REST_URL=https://your-redis-url.upstash.io
UPSTASH_REDIS_REST_TOKEN=your-redis-token
```

### Error Handling

**Scenario 1: Redis unavailable**
```typescript
try {
  // Attempt rate limit check
} catch (error) {
  log(LogLevel.ERROR, 'Redis connection failed', { error });
  // Fail open - allow request
  return { allowed: true, remaining: 999 };
}
```

**Scenario 2: Rate limit exceeded**
```typescript
if (!rateLimitResult.allowed) {
  throw new RateLimitError(rateLimitResult.resetAt);
  // Returns 429 status with user-friendly message
}
```

**Scenario 3: Invalid bypass code**
```typescript
if (code !== expectedCode) {
  return res.status(400).json({
    success: false,
    error: 'Invalid bypass code'
  });
}
```

---

## Security Model

### Multi-User SaaS Architecture (v1.1.x)

**The Database ID Mapping Problem:**

When a user duplicates the Sage Stocks template, Notion creates **completely new database IDs** unique to their workspace:

```
Template Creator:
  Stock Analyses DB = abc123...
  Stock History DB = def456...

User A (after duplication):
  Stock Analyses DB = xyz789...  (different!)
  Stock History DB = uvw012...  (different!)

User B (after duplication):
  Stock Analyses DB = lmn345...  (different!)
  Stock History DB = opq678...  (different!)
```

**Why Setup & Detection Are Critical:**

The backend needs to know **which databases belong to which user** to:

1. **Write analysis results to the correct user's database**
   - User A requests NVDA analysis â†’ writes to `xyz789...` (User A's Stock Analyses)
   - User B requests NVDA analysis â†’ writes to `lmn345...` (User B's Stock Analyses)
   - Prevents data leakage between users

2. **Query historical data from the correct user's database**
   - "User A's previous analyses" â†’ queries `xyz789...`
   - "User B's previous analyses" â†’ queries `lmn345...`

3. **Enforce per-user quotas and tracking**
   - User A: 3/5 analyses used today
   - User B: 1/5 analyses used today
   - Tracked in Beta Users database by user ID

4. **Personalize features based on user's data**
   - "You've analyzed 47 stocks this month" (counts pages in user's Stock Analyses DB)
   - "Your portfolio is heavy on tech sector" (reads user's holdings)

**The Setup Flow (First-Time Onboarding):**

1. **User duplicates template** â†’ Gets their own databases with unique IDs
2. **User logs in via Notion OAuth** â†’ System gets their email and OAuth token
3. **Auto-detection runs** (`/api/setup` GET):
   - Searches user's workspace for databases (using their OAuth token)
   - Scores each database against expected schema
   - Finds "Stock Analyses" and "Stock History" with high confidence
4. **User confirms or manually corrects** â†’ IDs validated and stored
5. **Backend stores mapping in Beta Users database:**
   ```
   Email: user@example.com
   Stock Analyses DB ID: xyz789...
   Stock History DB ID: uvw012...
   ```

**Every Future Request Uses This Mapping:**

```typescript
// User requests NVDA analysis
1. validateSession(req) â†’ email = "user@example.com"
2. getUserByEmail(email) â†’ row from Beta Users DB
3. stockAnalysesDbId = row.stockAnalysesDbId // "xyz789..."
4. Run analysis, write to xyz789... using user's OAuth token
5. Only their workspace is affected
```

**Security Benefits:**

- âœ… Each user's OAuth token can only access **their** workspace
- âœ… Backend never mixes data between users (scoped by database ID)
- âœ… User data never leaves their Notion workspace
- âœ… No shared databases = no data leakage risk
- âœ… Admin integration (NOTION_API_KEY) only accesses Beta Users DB (metadata only)

**What Breaks Without Setup:**

- âŒ Can't run analyses - don't know where to write results
- âŒ Can't support multiple users - would overwrite each other's data
- âŒ Can't track usage - don't know which user made which request
- âŒ Can't personalize - don't know user's historical data

This setup flow is the **foundation of the entire multi-user SaaS platform**. The auto-detection bug fix in v1.1.7 was critical because it would have forced all Cohort 1 users into manual fallback (30% abandonment rate).

---

### âš ï¸ CRITICAL: User-Specific Database IDs (v1.2.0+)

**The Rule:** NEVER use global environment variables for database IDs. ALWAYS use user-specific IDs from the user record.

**Why This Matters:**

In v1.2.0, we implemented the subway map setup flow where each user duplicates the template and gets their own unique database IDs stored in:
- `user.stockAnalysesDbId` - User's Stock Analyses database
- `user.stockHistoryDbId` - User's Stock History database
- `user.sageStocksPageId` - User's Sage Stocks page

**The Bug (Fixed in Production):**

Initially, both `api/analyze.ts` and `lib/orchestrator.ts` used global environment variables:

```typescript
// âŒ WRONG - Uses same database for ALL users
const stockAnalysesDbId = process.env.STOCK_ANALYSES_DB_ID;
const stockHistoryDbId = process.env.STOCK_HISTORY_DB_ID;
```

This caused:
- User A's analysis to write to User B's database (or fail completely)
- Orchestrator to query wrong databases for each user
- Complete multi-user failure

**The Fix:**

```typescript
// âœ… CORRECT - Uses each user's specific database
const stockAnalysesDbId = user.stockAnalysesDbId;
const stockHistoryDbId = user.stockHistoryDbId;

// Validate user has completed setup
if (!stockAnalysesDbId) {
  throw new Error('Stock Analyses database not configured. Please complete setup at https://sagestocks.vercel.app/');
}
```

**Files That MUST Use User-Specific IDs:**

1. **[api/analyze.ts](api/analyze.ts#L229-L231)** - Stock analysis endpoint
   ```typescript
   const stockAnalysesDbId = user.stockAnalysesDbId;
   const stockHistoryDbId = user.stockHistoryDbId;
   ```

2. **[lib/orchestrator.ts](lib/orchestrator.ts#L38-L48)** - Batch processing
   ```typescript
   export interface Subscriber {
     // ... other fields
     stockAnalysesDbId: string;  // User's specific DB ID
     stockHistoryDbId: string;   // User's specific DB ID
   }
   ```
   - Passes database IDs when creating subscribers
   - Uses `subscriber.stockAnalysesDbId` in `broadcastToUser()`

**Files That MAY Use Global Env Vars:**

- **[api/webhook.ts](api/webhook.ts)** - Admin operations only (uses `NOTION_API_KEY`, not OAuth)
- **Test scripts** - For development/testing purposes

**How to Verify Multi-User Support:**

```bash
# Check that user-specific IDs are used
grep -r "process.env.STOCK_ANALYSES_DB_ID" api/ lib/
# Should only appear in webhook.ts and test files

# Verify user object has database IDs
grep "stockAnalysesDbId" lib/auth.ts
# Should see it in User interface and mapNotionPageToUser()
```

**Testing Multi-User Scenarios:**

1. Create two test accounts with different email addresses
2. Each duplicates the template (gets unique database IDs)
3. User A analyzes AAPL â†’ verify it writes to User A's database
4. User B analyzes AAPL â†’ verify it writes to User B's database (separate instance)
5. Check that databases don't cross-contaminate

**Why This Architecture Decision:**

We chose user-specific duplicated templates over shared databases because:
- âœ… **Privacy** - Each user's data stays in their Notion workspace
- âœ… **Security** - OAuth tokens are scoped per workspace
- âœ… **Customization** - Users can modify their template without affecting others
- âœ… **Scalability** - Notion API rate limits are per-workspace, not shared
- âœ… **Data ownership** - Users own their analysis data

This is fundamentally different from traditional SaaS (shared PostgreSQL), but aligns with Notion's workspace model.

---

### Authentication
**Current:** Notion OAuth 2.0 (v1.1.1+)
- Official Notion OAuth integration
- Session token stored in encrypted cookie
- Token validated on every request
- User approval status checked (approved/pending/denied)

**User Identification:**
- Email from Notion OAuth
- Notion User ID from OAuth response
- Beta Users database lookup by email
- Database IDs retrieved from Beta Users record

### Authorization
**Rate Limiting:** Primary access control mechanism
- 10 analyses per user per day
- Bypass code for admin/beta testers
- No payment or subscription system (yet)

**Notion Integration:**
- Integration token stored in environment
- Scoped to specific workspace
- No user credentials stored

### Secrets Management
**Vercel Environment Variables:**
- API keys (FMP, FRED, Notion)
- Redis credentials (Upstash)
- Bypass code
- All secrets encrypted at rest

**Local Development:**
- `.env` file (gitignored)
- `.env.v1.example` template provided
- Secrets never committed to git

### Input Validation
**Ticker Symbols:**
- Alphanumeric + hyphen only
- Max length: 10 characters
- Uppercase normalization

**User IDs:**
- Alphanumeric + hyphen + underscore
- Max length: 100 characters
- Required for rate limiting

**Request Bodies:**
- JSON schema validation
- Type checking via TypeScript
- Zod schemas (optional validation)

### CORS Configuration
**Allowed Origins:** `*` (public API)
**Allowed Methods:** `GET, POST, OPTIONS`
**Allowed Headers:** `Content-Type, Authorization, X-API-Key`

**Rationale:** Personal tool, not sensitive data

### Error Handling
**User-Facing Errors:**
- No stack traces exposed
- Generic error messages
- HTTP status codes (400, 429, 500)

**Internal Logging:**
- Full error details logged
- Vercel logging dashboard
- No PII in logs

---

## Deployment Architecture

### Platform: Vercel Serverless

**Function Configuration:**
```json
{
  "functions": {
    "api/analyze.ts": { "maxDuration": 300 },               // 5 minutes
    "api/webhook.ts": { "maxDuration": 60 },                // 1 minute
    "api/health.ts": { "maxDuration": 10 },                 // 10 seconds
    "api/cron/scheduled-analyses.ts": { "maxDuration": 800 } // 13 minutes (Pro plan max with Fluid Compute)
  },
  "crons": [
    {
      "path": "/api/cron/scheduled-analyses",
      "schedule": "0 13 * * *"  // 5:00 AM PT (13:00 UTC) daily
    }
  ]
}
```

**Timeout Configuration (v1.0.6):**
- **Pro Plan Limit**: 800 seconds (13 minutes) with Vercel Fluid Compute
- **Cron Function**: Requires explicit `export const maxDuration = 800` in TypeScript file
- **Current Usage**: ~780 seconds for 13 stocks (~60s per stock)
- **Buffer**: 20-second margin for future growth
- **Node Version**: Pinned to `20.x` (prevents auto-upgrades)

**Build Process:**
1. TypeScript compilation (`tsc --noEmit` for type checking)
2. Vercel packages functions automatically
3. Deploy to edge network (global CDN)

**Cold Start Optimization:**
- Minimal dependencies
- Lazy loading of heavy libraries
- Connection pooling avoided (Redis REST API)

### CI/CD Pipeline

**GitHub Integration:**
```
1. Push to main branch (GitHub Desktop or CLI)
   â””â”€â–¶ Triggers Vercel deployment

2. Vercel Build
   â”œâ”€â–¶ Install dependencies (npm install)
   â”œâ”€â–¶ Type check (npm run type-check)
   â”œâ”€â–¶ Package functions
   â””â”€â–¶ Deploy to production

3. Deployment Complete (~30-60 seconds)
   â””â”€â–¶ Health check automatically validates
```

**Rollback:**
- Vercel dashboard allows instant rollback
- Each deployment preserved for 30 days
- Git history allows code-level rollback

### Environment Management

**Production (Vercel):**
- All secrets in Vercel dashboard
- Environment variables encrypted
- Accessible only to functions at runtime

**Local Development:**
- `.env` file with dev credentials
- `vercel dev` command for testing
- Test scripts (`npm run test:analyze`)

### Monitoring

**Vercel Dashboard:**
- Function execution logs
- Error rates and stack traces
- Performance metrics (duration, cold starts)
- Rate limit tracking (manual via logs)

**Logging Strategy:**
- `LogLevel.INFO` - Request lifecycle
- `LogLevel.WARN` - Graceful failures (Redis down)
- `LogLevel.ERROR` - Unexpected errors

---

## Configuration

### Environment Variables

```bash
# === Core API Keys ===
NOTION_API_TOKEN=secret_xxxxxxxxxxxxx
FMP_API_KEY=your_fmp_api_key_here
FRED_API_KEY=your_fred_api_key_here

# === Notion Database IDs ===
NOTION_ANALYSES_DB_ID=xxxxxxxxxxxxxxxx
NOTION_HISTORY_DB_ID=xxxxxxxxxxxxxxxx

# === Rate Limiting (Upstash Redis) ===
UPSTASH_REDIS_REST_URL=https://your-redis-url.upstash.io
UPSTASH_REDIS_REST_TOKEN=your_redis_token_here
RATE_LIMIT_ENABLED=true
RATE_LIMIT_MAX_ANALYSES=10
RATE_LIMIT_BYPASS_CODE=your_bypass_code_here

# === Authentication ===
API_KEY=your_api_key_here

# === Optional: Development ===
NODE_ENV=development
LOG_LEVEL=INFO
```

### Scoring Configuration

**File:** `config/scoring-config.ts` and `lib/scoring.ts`

**Current Composite Score Weights (v1.1.6):**
- **Technical Score: 30%** - Price action, momentum, volume, RSI, MACD
- **Fundamental Score: 35%** - Financials, valuation, P/E ratio, EPS, debt/equity
- **Macro Score: 20%** - Economic conditions, Fed policy, yield curve, VIX
- **Risk Score: 15%** - Volatility, beta, market cap

**Note:** Sentiment and Sector scores are calculated independently but NOT weighted in the composite score (they provide additional context).

**âš ï¸ Historical Note:** Earlier versions (v1.0.0-alpha) used different weights. Current production weights are documented in [lib/scoring.ts:73-78](lib/scoring.ts#L73-L78).

**Score Scale:**
- All individual scores: 1.0-5.0 scale
- Composite score: Weighted average of Technical + Fundamental + Macro + Risk

**Recommendation Boundaries:**
- Strong Buy: 4.5-5.0
- Buy: 3.5-4.4
- Hold: 2.5-3.4
- Sell: 1.5-2.4
- Strong Sell: 1.0-1.4

**Customizable:** Edit `lib/scoring.ts` weights and redeploy

### Notion Schema

**File:** `config/notion-schema.ts`

**Property Mappings:**
- Ticker â†’ Title property
- Scores â†’ Number properties
- Recommendation â†’ Select property
- Pattern â†’ Select property

**Flexible:** Supports custom property names

---

## Design Decisions

### 1. **Serverless Architecture**
**Decision:** Use Vercel serverless functions instead of long-running servers

**Rationale:**
- No server maintenance required
- Auto-scaling (0 to N instances)
- Pay only for usage (~$0/month at current scale)
- Global edge network (low latency)

**Trade-offs:**
- Cold starts (~1-2 seconds)
- No persistent connections (hence Redis REST API)
- Function timeout limits (300 seconds max on Pro)

---

### 2. **Upstash Redis for Rate Limiting**
**Decision:** Use Upstash Redis instead of Vercel KV or Edge Config

**Rationale:**
- Better free tier (10,000 commands vs 1,000 requests)
- REST API perfect for serverless (no TCP connections)
- Built-in TTL expiry (automatic midnight reset)
- Industry-standard Redis commands

**Alternatives Considered:**
- Vercel KV: More expensive, similar features
- Edge Config: Read-only, not suitable for counters
- Database: Too slow, overkill for counters

---

### 3. **Session-Based Bypass Codes**
**Decision:** Store bypass sessions in Redis instead of passing code with every request

**Rationale:**
- Better UX (enter code once, use all day)
- More secure (code not exposed in URLs/logs repeatedly)
- Easy revocation (change environment variable)
- Automatic expiry (midnight UTC)

**Alternatives Considered:**
- Stateless JWT: More complex, harder to revoke
- API key per user: Requires user management system
- No bypass: Blocks admin testing

---

### 4. **TypeScript Over JavaScript**
**Decision:** Use TypeScript for all code

**Rationale:**
- Type safety catches errors at compile time
- Better IDE support (autocomplete, refactoring)
- Self-documenting code (types as documentation)
- Industry standard for production systems

**Trade-offs:**
- Compilation step required
- Slight learning curve

---

### 5. **Notion as Primary UI**
**Decision:** Use Notion databases instead of building custom web UI

**Rationale:**
- User already lives in Notion
- Zero frontend maintenance
- Flexible schema (Notion handles CRUD)
- AI integration built-in (Notion AI)

**Trade-offs:**
- Notion API rate limits (3 req/sec)
- Webhook limitations (discovered in v1.0.1)
- Dependent on third-party platform

---

### 6. **Fail Open on Redis Errors**
**Decision:** Allow requests if Redis is unavailable

**Rationale:**
- Personal tool, not mission-critical
- Better UX than hard failures
- Temporary outages shouldn't block usage

**Alternatives Considered:**
- Fail closed: More secure but worse UX
- Queue requests: Too complex for personal tool

---

### 7. **FMP + FRED Over Polygon/Alpha Vantage**
**Decision:** Consolidated to FMP for stock data + FRED for macros

**Rationale:**
- Single provider simplifies integration
- FMP has all needed data (technical + fundamental)
- FRED is authoritative for macro data (Federal Reserve)
- Cost-effective ($22-29/month vs $200+ for Polygon)

**Previous Stack (v0.x):**
- Polygon + Alpha Vantage + FRED
- More expensive, more API keys to manage

---

### 8. **No Frontend Framework (Yet)**
**Decision:** Backend-only system, Notion for UI

**Rationale:**
- Simplicity (no React/Next.js complexity)
- Faster development (focus on API logic)
- User preference (Notion-native workflow)

**Future Consideration:**
- v1.0.1 exploring Notion-native vs HTML vs Next.js
- Phased validation approach (build simplest first)

---

### 9. **Global CORS (Allow All Origins)**
**Decision:** Allow all origins instead of whitelisting

**Rationale:**
- Public API, not sensitive data
- Simplifies Notion webhook integration
- Personal tool, not enterprise system

**Security Note:**
- Rate limiting provides primary access control
- No user credentials exposed
- All secrets server-side only

---

### 10. **Composite Scoring Model**
**Decision:** Weighted combination of technical + fundamental scores

**Rationale:**
- Balanced view (not just charts, not just financials)
- Customizable weights (60/40 current split)
- Pattern matching adds context (breakout, reversal)

**Alternative Considered:**
- ML-based scoring: Too complex, requires training data
- Single-dimension scoring: Misses important signals

---

### 11. **Critical Operations Require Retry Logic**
**Decision:** All critical Notion API operations use retry logic with exponential backoff (v1.2.3)

**Rationale:**
- Notion API has occasional service outages (`service_unavailable` errors)
- Critical operations (like saving database IDs during setup) cannot silently fail
- Retry logic converts transient failures into successful operations
- Better UX than immediate failure or long timeouts

**Implementation:**
- `withRetry` utility with 3 attempts, exponential backoff (2s, 4s, 8s delays)
- Total retry time: ~14 seconds (vs 10-minute timeout)
- Preserve Notion error codes (`NOTION_SERVICE_UNAVAILABLE`, `NOTION_RATE_LIMITED`)
- `isRetryableError` identifies transient vs permanent failures

**Critical Operations Using Retry Logic:**
1. **getUserByEmail** ([lib/auth.ts](lib/auth.ts))
   - Used in setup detection and analysis endpoints
   - Preserves specific Notion error codes for retry decisions
   - Prevents immediate failure on temporary Notion outages

2. **updateUserDatabaseIds** ([api/setup/detect.ts](api/setup/detect.ts))
   - Saves stockAnalysesDbId, stockHistoryDbId, sageStocksPageId
   - **Marked as CRITICAL** - setup fails if this doesn't succeed
   - Prevents "silent failure" where setup shows success but analysis fails later

**Key Learnings (v1.2.3 Bug Fix):**

**Problem:** Setup would show "success" but first analysis would fail with "Database not configured"
- Root cause: `updateUserDatabaseIds` was marked "non-critical" and silently failed during Notion outages
- Database IDs weren't saved, but user saw "Setup complete!"

**Solution:**
1. Never mark critical operations as "non-critical" - if the system can't work without it, it must succeed or fail explicitly
2. Preserve error codes - don't swallow specific errors with generic messages
3. Add retry logic to all Notion API calls in critical paths
4. Fail fast with clear errors - don't let operations appear successful when they haven't completed

**Alternatives Considered:**
- No retry logic: Too brittle, poor UX during Notion outages
- Infinite retries: Risk of hanging requests
- Circuit breaker: Too complex for current scale

**Future Consideration:**
- Circuit breaker pattern if Notion outages become more frequent
- Health check endpoint to pre-validate Notion availability

---

### 12. **LLM Hallucination Prevention via Data Grounding & Historical Isolation**
**Decision:** Ground LLM analysis in 100% factual API data and isolate historical context with explicit warnings (v1.0.6)

**Problem Context:**

Stock analyses suffered from two critical hallucination issues:
1. **Temporal Confusion:** LLM referenced "December 2024" and "Q4 2024" as future events in November 2025
2. **Price Hallucination:** Entry zones showed $168-174 when actual price was $276.98 (~40% below market)

**Root Causes:**
1. `currentMetrics` object only contained **scores**, not raw API data (price, volume, P/E, etc.)
2. No `currentDate` field in `AnalysisContext` - LLM had no temporal awareness
3. Historical analysis dates (e.g., `previousAnalysis.date = "2024-12-15"`) "leaked" into current analysis
4. LLM pattern-matched historical dates without warnings â†’ used them as future catalysts

**Solution Implementation:**

**1. Data Grounding (33 New Fields Added to Context)**

Expanded `currentMetrics` from 7 fields (scores only) to 40 fields (all API data):

```typescript
// BEFORE (api/analyze.ts:586)
const analysisContext: AnalysisContext = {
  ticker: tickerUpper,
  currentMetrics: {
    compositeScore: scores.composite,
    technicalScore: scores.technical,
    fundamentalScore: scores.fundamental,
    // ... only 7 score fields
  }
};

// AFTER (api/analyze.ts:586-638)
const analysisContext: AnalysisContext = {
  ticker: tickerUpper,
  currentDate: new Date().toISOString().split('T')[0], // "2025-11-16"
  currentMetrics: {
    // Scores (7 fields - original)
    compositeScore: scores.composite,
    technicalScore: scores.technical,
    // ... etc

    // Company Profile (3 new fields)
    companyName: fundamental.company_name,
    sector: fmpData.profile.sector,
    industry: fmpData.profile.industry,

    // Technical Data (11 new fields - ALL from FMP API)
    currentPrice: technical.current_price,  // â† Fixes price hallucination
    ma50: technical.ma_50,
    ma200: technical.ma_200,
    rsi: technical.rsi,
    volume: technical.volume,
    avgVolume: technical.avg_volume_20d,
    volatility30d: technical.volatility_30d,
    priceChange1d: technical.price_change_1d,
    priceChange5d: technical.price_change_5d,
    priceChange1m: technical.price_change_1m,
    week52High: technical.week_52_high,
    week52Low: technical.week_52_low,

    // Fundamental Data (6 new fields - ALL from FMP API)
    marketCap: fundamental.market_cap,
    peRatio: fundamental.pe_ratio,
    eps: fundamental.eps,
    revenueTTM: fundamental.revenue_ttm,
    debtToEquity: fundamental.debt_to_equity,
    beta: fundamental.beta,

    // Macro Data (6 new fields - ALL from FRED API)
    fedFundsRate: macro.fed_funds_rate,
    unemployment: macro.unemployment,
    consumerSentiment: macro.consumer_sentiment,
    yieldCurveSpread: macro.yield_curve_spread,
    vix: macro.vix,
    gdp: macro.gdp,
  }
};
```

**2. Historical Data Isolation Pattern**

Wrapped all historical dates with explicit before/after warnings:

```typescript
// lib/llm/prompts/shared.ts:160-178
if (previousAnalysis && deltas) {
  prompt += `**Changes Since Previous Analysis (${deltas.priceDeltas?.daysElapsed || '?'} days ago):**\n`;

  // âš ï¸ WARNING BEFORE
  prompt += `âš ï¸ NOTE: The date "${previousAnalysis.date}" below is HISTORICAL REFERENCE ONLY. Do NOT use it in your "Key Dates" section!\n\n`;

  // Historical data shown here
  prompt += `- Previous analysis: ${previousAnalysis.date} (${deltas.priceDeltas?.daysElapsed || '?'} days ago - this is PAST data for comparison only)\n`;
  // ... delta details

  // âš ï¸ WARNING AFTER
  prompt += `\nâš ï¸ REMINDER: The date ${previousAnalysis.date} above is in the PAST. It is for historical comparison ONLY. Do NOT reference it in "Key Dates" or as a future catalyst.\n\n`;
}
```

**3. Multi-Layer Temporal Awareness**

Created four defensive layers:

**Layer 1: Date Calculation & Display** ([lib/llm/prompts/shared.ts:182-231](lib/llm/prompts/shared.ts:182-231))
```typescript
const [year, month] = currentDate.split('-').map(Number);
const currentQuarter = Math.ceil(month / 3); // Q1=1-3, Q2=4-6, Q3=7-9, Q4=10-12

// Build explicit past/future quarter lists
const pastQuarters: string[] = [];    // ["Q1 2024", "Q2 2024", "Q3 2024", "Q4 2024"]
const futureQuarters: string[] = [];  // ["Q4 2025", "Q1 2026", "Q2 2026", ...]
```

**Layer 2: Forbidden Phrases Blacklist**
```typescript
prompt += `**FORBIDDEN PHRASES (DO NOT USE THESE):**\n`;
prompt += `- âŒ ANY mention of "${year - 1}" as a future date\n`;
prompt += `- âŒ "December ${year - 1}" / "Dec ${year - 1}"\n`;
prompt += `- âŒ "Q4 ${year - 1} earnings" (unless clearly marked as PAST)\n`;
prompt += `- âŒ "Check Q4 ${year - 1} calendar"\n`;
```

**Layer 3: Allowed Phrases Whitelist**
```typescript
prompt += `**ALLOWED PHRASES (Use these instead):**\n`;
prompt += `- âœ… "Next earnings report" / "Upcoming earnings"\n`;
prompt += `- âœ… "Next Fed meeting" / "Upcoming Fed decision"\n`;
prompt += `- âœ… "Q${currentQuarter} ${year} earnings" (current quarter)\n`;
```

**Layer 4: Output Template Constraints** ([lib/llm/prompts/shared.ts:253-259](lib/llm/prompts/shared.ts:253-259))
```typescript
prompt += `**Key Dates Section Rules (CRITICAL):**\n`;
prompt += `- The "Key Dates" section in your output MUST contain ONLY future events\n`;
prompt += `- Use generic language ONLY: "Upcoming earnings", "Next Fed meeting"\n`;
prompt += `- DO NOT use dates from the "Changes Since Previous Analysis" section above - those are PAST dates for comparison only\n`;
```

**Rationale:**

**Why Data Grounding is Critical:**
- LLMs hallucinate when lacking factual grounding in prompt context
- Training data is outdated (cutoff dates vary by model)
- Scores alone don't anchor LLM to reality - need raw numbers (price, volume, P/E, etc.)
- Contextual comparisons (e.g., "currently at 73% of 52-week range") prevent numeric hallucination

**Why Historical Isolation is Critical:**
- LLMs are pattern-matching machines, not temporal reasoners
- Seeing "2024-12-15" in context â†’ LLM infers "Q4 2024" is relevant â†’ uses it in output
- Without explicit warnings, LLM treats all dates in context as potentially current/future
- Multi-layer constraints needed because single warnings are easily ignored

**Impact:**

âœ… **Eliminates temporal hallucinations** - Past dates no longer referenced as future
âœ… **Eliminates price hallucinations** - LLM uses real-time API data ($276.98) instead of training data ($168-174)
âœ… **Systemic protection** - All future analyses inherit these safeguards via shared prompt template
âœ… **Defensive prompt design** - Assumes LLM will fail unless explicitly constrained

**Files Modified:**
- [lib/llm/types.ts](lib/llm/types.ts) - Added `currentDate` field to `AnalysisContext`
- [api/analyze.ts](api/analyze.ts) - Expanded `currentMetrics` (7 fields â†’ 40 fields)
- [lib/stock-analyzer.ts](lib/stock-analyzer.ts) - Same changes for orchestrator path
- [lib/llm/prompts/shared.ts](lib/llm/prompts/shared.ts) - 300+ lines rewritten with data display + temporal logic

**Architectural Principles Established:**

**1. LLM Prompt Engineering Best Practices**
- **Ground in Facts:** Pass ALL raw API data, not just derived scores
- **Isolate Historical Context:** Wrap past dates with before/after warnings
- **Multi-Layer Constraints:** Blacklists + whitelists + examples + output rules
- **Explicit Temporal Logic:** Calculate and display current date, year, quarter, past/future lists
- **Defensive Design:** Assume LLM will pattern-match historical data unless explicitly blocked

**2. Historical Data Isolation Pattern (Reusable)**
```
âš ï¸ WARNING: <historical_date> is PAST data for comparison only
<historical data shown here>
âš ï¸ REMINDER: Do NOT use <historical_date> in current analysis
```

This pattern must be applied to:
- Previous stock analyses (âœ… implemented)
- Historical stock prices (future consideration)
- Past earnings reports (future consideration)
- Any temporal context that could confuse LLM

**3. Context Expansion Strategy**
- Always pass raw API data, not just aggregated/derived values
- Add contextual comparisons (e.g., "73% of 52-week range", "+12.3% above MA50")
- Include interpretations (e.g., "RSI 75 (overbought)", "P/E 28.5 (high vs sector avg)")
- More context = less hallucination = higher quality output

**Trade-offs:**

**Cons:**
- Increased prompt token count (~500 tokens added)
- Slightly higher LLM API costs ($0.013 â†’ $0.015 per analysis)
- More complex prompt maintenance (300+ line template)

**Pros:**
- Eliminated hallucinations completely (verified with GOOG analysis)
- Grounded in 100% factual real-time data
- Protects ALL future analyses from this class of bugs
- Clear documentation prevents regression

**Alternatives Considered:**

1. **LLM Fine-Tuning:** Too expensive, requires training data, doesn't solve temporal awareness
2. **Post-Processing Validation:** Would catch errors but not prevent them, worse UX
3. **Simpler Prompts:** Tested - LLM ignored subtle hints, needs explicit constraints
4. **Single Warning Layer:** Insufficient - LLM pattern-matched historical dates despite warnings

**Future Considerations:**

1. **Automated Prompt Testing:** Create test suite to validate temporal awareness
2. **Token Usage Monitoring:** Track prompt token growth as more fields are added
3. **Context Compression:** If tokens become issue, use tabular format instead of prose
4. **Provider Comparison:** Test if different LLMs (GPT-4, Claude) need different constraint styles

**Key Learning:**

LLM hallucinations are **architectural issues**, not bugs. They require **systematic prevention** via:
- Comprehensive data grounding (pass all factual context)
- Explicit constraints (blacklists, whitelists, examples)
- Historical data isolation (warnings before/after past dates)
- Multi-layer reinforcement (don't rely on single defense)

This fix establishes a **defensive prompt engineering pattern** that should be applied to all LLM integrations in the system.

---

## Future Enhancements

### v1.1: Enhanced Analysis Features
- Insider trading analysis (requires FMP Pro upgrade)
- Market regime classification (Risk-On/Risk-Off)
- Sector strength rankings
- Brave Search API for market intelligence

### v2.0: Full Automation
- Scheduled jobs (GitHub Actions/Vercel Cron)
- Autonomous portfolio monitoring
- Intelligent digest notifications
- Historical trend analysis
- Market Context dashboard

### Infrastructure
- Upstash Redis Analytics (monitoring usage patterns)
- Vercel Pro upgrade (300-second timeouts)
- CDN caching for repeated tickers
- WebSocket support for real-time updates

---

## Additional Resources

**Setup Documentation:**
- [SETUP.md](SETUP.md) - Environment setup and deployment
- [TESTING.md](TESTING.md) - Testing procedures and validation
- [ROADMAP.md](ROADMAP.md) - Project roadmap and progress

**Rate Limiting Documentation:**
- [RATE_LIMITING_SETUP.md](RATE_LIMITING_SETUP.md) - Complete Upstash setup guide
- [.env.v1.example](.env.v1.example) - Environment variable template

**User Settings Documentation:**
- [USER_SETTINGS_PHASE1.md](USER_SETTINGS_PHASE1.md) - Notion-native implementation
- [PHASE1_QUICKSTART.md](PHASE1_QUICKSTART.md) - Quick start guide
- [PHASE1_WEBHOOK_UPDATE.md](PHASE1_WEBHOOK_UPDATE.md) - Webhook blocker fix

---

**Questions or Issues?**
Contact: Shalom Ormsby
Project Repository: [GitHub](https://github.com/shalomormsby/stock-intelligence) (if applicable)
